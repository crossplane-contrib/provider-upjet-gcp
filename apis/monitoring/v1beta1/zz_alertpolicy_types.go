// SPDX-FileCopyrightText: 2023 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

/*
Copyright 2021 The Crossplane Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Code generated by upjet. DO NOT EDIT.

package v1beta1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AggregationsInitParameters struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type AggregationsObservation struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type AggregationsParameters struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	// +kubebuilder:validation:Optional
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	// +kubebuilder:validation:Optional
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	// +kubebuilder:validation:Optional
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	// +kubebuilder:validation:Optional
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type AlertPolicyInitParameters struct {

	// Control over how this alert policy's notification channels are notified.
	// Structure is documented below.
	AlertStrategy []AlertStrategyInitParameters `json:"alertStrategy,omitempty" tf:"alert_strategy,omitempty"`

	// How to combine the results of multiple conditions to
	// determine if an incident should be opened.
	// Possible values are: AND, OR, AND_WITH_MATCHING_RESOURCE.
	Combiner *string `json:"combiner,omitempty" tf:"combiner,omitempty"`

	// A list of conditions for the policy. The conditions are combined by
	// AND or OR according to the combiner field. If the combined conditions
	// evaluate to true, then an incident is created. A policy can have from
	// one to six conditions.
	// Structure is documented below.
	Conditions []ConditionsInitParameters `json:"conditions,omitempty" tf:"conditions,omitempty"`

	// A short name or phrase used to identify the policy in
	// dashboards, notifications, and incidents. To avoid confusion, don't use
	// the same display name for multiple policies in the same project. The
	// name is limited to 512 Unicode characters.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// Documentation that is included with notifications and incidents related
	// to this policy. Best practice is for the documentation to include information
	// to help responders understand, mitigate, escalate, and correct the underlying
	// problems detected by the alerting policy. Notification channels that have
	// limited capacity might not show this documentation.
	// Structure is documented below.
	Documentation []DocumentationInitParameters `json:"documentation,omitempty" tf:"documentation,omitempty"`

	// Whether or not the policy is enabled. The default is true.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// Identifies the notification channels to which notifications should be
	// sent when incidents are opened or closed or when new violations occur
	// on an already opened incident. Each element of this array corresponds
	// to the name field in each of the NotificationChannel objects that are
	// returned from the notificationChannels.list method. The syntax of the
	// entries in this field is
	// projects/[PROJECT_ID]/notificationChannels/[CHANNEL_ID]
	NotificationChannels []*string `json:"notificationChannels,omitempty" tf:"notification_channels,omitempty"`

	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project *string `json:"project,omitempty" tf:"project,omitempty"`

	// This field is intended to be used for organizing and identifying the AlertPolicy
	// objects.The field can contain up to 64 entries. Each key and value is limited
	// to 63 Unicode characters or 128 bytes, whichever is smaller. Labels and values
	// can contain only lowercase letters, numerals, underscores, and dashes. Keys
	// must begin with a letter.
	// +mapType=granular
	UserLabels map[string]*string `json:"userLabels,omitempty" tf:"user_labels,omitempty"`
}

type AlertPolicyObservation struct {

	// Control over how this alert policy's notification channels are notified.
	// Structure is documented below.
	AlertStrategy []AlertStrategyObservation `json:"alertStrategy,omitempty" tf:"alert_strategy,omitempty"`

	// How to combine the results of multiple conditions to
	// determine if an incident should be opened.
	// Possible values are: AND, OR, AND_WITH_MATCHING_RESOURCE.
	Combiner *string `json:"combiner,omitempty" tf:"combiner,omitempty"`

	// A list of conditions for the policy. The conditions are combined by
	// AND or OR according to the combiner field. If the combined conditions
	// evaluate to true, then an incident is created. A policy can have from
	// one to six conditions.
	// Structure is documented below.
	Conditions []ConditionsObservation `json:"conditions,omitempty" tf:"conditions,omitempty"`

	// A read-only record of the creation of the alerting policy.
	// If provided in a call to create or update, this field will
	// be ignored.
	// Structure is documented below.
	CreationRecord []CreationRecordObservation `json:"creationRecord,omitempty" tf:"creation_record,omitempty"`

	// A short name or phrase used to identify the policy in
	// dashboards, notifications, and incidents. To avoid confusion, don't use
	// the same display name for multiple policies in the same project. The
	// name is limited to 512 Unicode characters.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// Documentation that is included with notifications and incidents related
	// to this policy. Best practice is for the documentation to include information
	// to help responders understand, mitigate, escalate, and correct the underlying
	// problems detected by the alerting policy. Notification channels that have
	// limited capacity might not show this documentation.
	// Structure is documented below.
	Documentation []DocumentationObservation `json:"documentation,omitempty" tf:"documentation,omitempty"`

	// Whether or not the policy is enabled. The default is true.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// an identifier for the resource with format {{name}}
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// The unique resource name for this policy.
	// Its syntax is: projects/[PROJECT_ID]/alertPolicies/[ALERT_POLICY_ID]
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Identifies the notification channels to which notifications should be
	// sent when incidents are opened or closed or when new violations occur
	// on an already opened incident. Each element of this array corresponds
	// to the name field in each of the NotificationChannel objects that are
	// returned from the notificationChannels.list method. The syntax of the
	// entries in this field is
	// projects/[PROJECT_ID]/notificationChannels/[CHANNEL_ID]
	NotificationChannels []*string `json:"notificationChannels,omitempty" tf:"notification_channels,omitempty"`

	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project *string `json:"project,omitempty" tf:"project,omitempty"`

	// This field is intended to be used for organizing and identifying the AlertPolicy
	// objects.The field can contain up to 64 entries. Each key and value is limited
	// to 63 Unicode characters or 128 bytes, whichever is smaller. Labels and values
	// can contain only lowercase letters, numerals, underscores, and dashes. Keys
	// must begin with a letter.
	// +mapType=granular
	UserLabels map[string]*string `json:"userLabels,omitempty" tf:"user_labels,omitempty"`
}

type AlertPolicyParameters struct {

	// Control over how this alert policy's notification channels are notified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	AlertStrategy []AlertStrategyParameters `json:"alertStrategy,omitempty" tf:"alert_strategy,omitempty"`

	// How to combine the results of multiple conditions to
	// determine if an incident should be opened.
	// Possible values are: AND, OR, AND_WITH_MATCHING_RESOURCE.
	// +kubebuilder:validation:Optional
	Combiner *string `json:"combiner,omitempty" tf:"combiner,omitempty"`

	// A list of conditions for the policy. The conditions are combined by
	// AND or OR according to the combiner field. If the combined conditions
	// evaluate to true, then an incident is created. A policy can have from
	// one to six conditions.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	Conditions []ConditionsParameters `json:"conditions,omitempty" tf:"conditions,omitempty"`

	// A short name or phrase used to identify the policy in
	// dashboards, notifications, and incidents. To avoid confusion, don't use
	// the same display name for multiple policies in the same project. The
	// name is limited to 512 Unicode characters.
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// Documentation that is included with notifications and incidents related
	// to this policy. Best practice is for the documentation to include information
	// to help responders understand, mitigate, escalate, and correct the underlying
	// problems detected by the alerting policy. Notification channels that have
	// limited capacity might not show this documentation.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	Documentation []DocumentationParameters `json:"documentation,omitempty" tf:"documentation,omitempty"`

	// Whether or not the policy is enabled. The default is true.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// Identifies the notification channels to which notifications should be
	// sent when incidents are opened or closed or when new violations occur
	// on an already opened incident. Each element of this array corresponds
	// to the name field in each of the NotificationChannel objects that are
	// returned from the notificationChannels.list method. The syntax of the
	// entries in this field is
	// projects/[PROJECT_ID]/notificationChannels/[CHANNEL_ID]
	// +kubebuilder:validation:Optional
	NotificationChannels []*string `json:"notificationChannels,omitempty" tf:"notification_channels,omitempty"`

	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	// +kubebuilder:validation:Optional
	Project *string `json:"project,omitempty" tf:"project,omitempty"`

	// This field is intended to be used for organizing and identifying the AlertPolicy
	// objects.The field can contain up to 64 entries. Each key and value is limited
	// to 63 Unicode characters or 128 bytes, whichever is smaller. Labels and values
	// can contain only lowercase letters, numerals, underscores, and dashes. Keys
	// must begin with a letter.
	// +kubebuilder:validation:Optional
	// +mapType=granular
	UserLabels map[string]*string `json:"userLabels,omitempty" tf:"user_labels,omitempty"`
}

type AlertStrategyInitParameters struct {

	// If an alert policy that was active has no data for this long, any open incidents will close.
	AutoClose *string `json:"autoClose,omitempty" tf:"auto_close,omitempty"`

	// Control over how the notification channels in notification_channels
	// are notified when this alert fires, on a per-channel basis.
	// Structure is documented below.
	NotificationChannelStrategy []NotificationChannelStrategyInitParameters `json:"notificationChannelStrategy,omitempty" tf:"notification_channel_strategy,omitempty"`

	// Required for alert policies with a LogMatch condition.
	// This limit is not implemented for alert policies that are not log-based.
	// Structure is documented below.
	NotificationRateLimit []NotificationRateLimitInitParameters `json:"notificationRateLimit,omitempty" tf:"notification_rate_limit,omitempty"`
}

type AlertStrategyObservation struct {

	// If an alert policy that was active has no data for this long, any open incidents will close.
	AutoClose *string `json:"autoClose,omitempty" tf:"auto_close,omitempty"`

	// Control over how the notification channels in notification_channels
	// are notified when this alert fires, on a per-channel basis.
	// Structure is documented below.
	NotificationChannelStrategy []NotificationChannelStrategyObservation `json:"notificationChannelStrategy,omitempty" tf:"notification_channel_strategy,omitempty"`

	// Required for alert policies with a LogMatch condition.
	// This limit is not implemented for alert policies that are not log-based.
	// Structure is documented below.
	NotificationRateLimit []NotificationRateLimitObservation `json:"notificationRateLimit,omitempty" tf:"notification_rate_limit,omitempty"`
}

type AlertStrategyParameters struct {

	// If an alert policy that was active has no data for this long, any open incidents will close.
	// +kubebuilder:validation:Optional
	AutoClose *string `json:"autoClose,omitempty" tf:"auto_close,omitempty"`

	// Control over how the notification channels in notification_channels
	// are notified when this alert fires, on a per-channel basis.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	NotificationChannelStrategy []NotificationChannelStrategyParameters `json:"notificationChannelStrategy,omitempty" tf:"notification_channel_strategy,omitempty"`

	// Required for alert policies with a LogMatch condition.
	// This limit is not implemented for alert policies that are not log-based.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	NotificationRateLimit []NotificationRateLimitParameters `json:"notificationRateLimit,omitempty" tf:"notification_rate_limit,omitempty"`
}

type ConditionAbsentInitParameters struct {

	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	Aggregations []AggregationsInitParameters `json:"aggregations,omitempty" tf:"aggregations,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	Trigger []TriggerInitParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionAbsentObservation struct {

	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	Aggregations []AggregationsObservation `json:"aggregations,omitempty" tf:"aggregations,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	Trigger []TriggerObservation `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionAbsentParameters struct {

	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	Aggregations []AggregationsParameters `json:"aggregations,omitempty" tf:"aggregations,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	Duration *string `json:"duration" tf:"duration,omitempty"`

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	Trigger []TriggerParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionMatchedLogInitParameters struct {

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// A map from a label key to an extractor expression, which is used to
	// extract the value for this label key. Each entry in this map is
	// a specification for how data should be extracted from log entries that
	// match filter. Each combination of extracted values is treated as
	// a separate rule for the purposes of triggering notifications.
	// Label keys and corresponding values can be used in notifications
	// generated by this condition.
	// +mapType=granular
	LabelExtractors map[string]*string `json:"labelExtractors,omitempty" tf:"label_extractors,omitempty"`
}

type ConditionMatchedLogObservation struct {

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// A map from a label key to an extractor expression, which is used to
	// extract the value for this label key. Each entry in this map is
	// a specification for how data should be extracted from log entries that
	// match filter. Each combination of extracted values is treated as
	// a separate rule for the purposes of triggering notifications.
	// Label keys and corresponding values can be used in notifications
	// generated by this condition.
	// +mapType=granular
	LabelExtractors map[string]*string `json:"labelExtractors,omitempty" tf:"label_extractors,omitempty"`
}

type ConditionMatchedLogParameters struct {

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	Filter *string `json:"filter" tf:"filter,omitempty"`

	// A map from a label key to an extractor expression, which is used to
	// extract the value for this label key. Each entry in this map is
	// a specification for how data should be extracted from log entries that
	// match filter. Each combination of extracted values is treated as
	// a separate rule for the purposes of triggering notifications.
	// Label keys and corresponding values can be used in notifications
	// generated by this condition.
	// +kubebuilder:validation:Optional
	// +mapType=granular
	LabelExtractors map[string]*string `json:"labelExtractors,omitempty" tf:"label_extractors,omitempty"`
}

type ConditionMonitoringQueryLanguageInitParameters struct {

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	EvaluationMissingData *string `json:"evaluationMissingData,omitempty" tf:"evaluation_missing_data,omitempty"`

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	Query *string `json:"query,omitempty" tf:"query,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	Trigger []ConditionMonitoringQueryLanguageTriggerInitParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionMonitoringQueryLanguageObservation struct {

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	EvaluationMissingData *string `json:"evaluationMissingData,omitempty" tf:"evaluation_missing_data,omitempty"`

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	Query *string `json:"query,omitempty" tf:"query,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	Trigger []ConditionMonitoringQueryLanguageTriggerObservation `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionMonitoringQueryLanguageParameters struct {

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	Duration *string `json:"duration" tf:"duration,omitempty"`

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	// +kubebuilder:validation:Optional
	EvaluationMissingData *string `json:"evaluationMissingData,omitempty" tf:"evaluation_missing_data,omitempty"`

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	// +kubebuilder:validation:Optional
	Query *string `json:"query" tf:"query,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	Trigger []ConditionMonitoringQueryLanguageTriggerParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionMonitoringQueryLanguageTriggerInitParameters struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type ConditionMonitoringQueryLanguageTriggerObservation struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type ConditionMonitoringQueryLanguageTriggerParameters struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type ConditionPrometheusQueryLanguageInitParameters struct {

	// The alerting rule name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	AlertRule *string `json:"alertRule,omitempty" tf:"alert_rule,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// How often this rule should be evaluated. Must be a positive multiple
	// of 30 seconds or missing. The default value is 30 seconds. If this
	// PrometheusQueryLanguageCondition was generated from a Prometheus
	// alerting rule, then this value should be taken from the enclosing
	// rule group.
	EvaluationInterval *string `json:"evaluationInterval,omitempty" tf:"evaluation_interval,omitempty"`

	// Labels to add to or overwrite in the PromQL query result. Label names
	// must be valid.
	// Label values can be templatized by using variables. The only available
	// variable names are the names of the labels in the PromQL result, including
	// "name" and "value". "labels" may be empty. This field is intended to be
	// used for organizing and identifying the AlertPolicy
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	Query *string `json:"query,omitempty" tf:"query,omitempty"`

	// The rule group name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	RuleGroup *string `json:"ruleGroup,omitempty" tf:"rule_group,omitempty"`
}

type ConditionPrometheusQueryLanguageObservation struct {

	// The alerting rule name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	AlertRule *string `json:"alertRule,omitempty" tf:"alert_rule,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// How often this rule should be evaluated. Must be a positive multiple
	// of 30 seconds or missing. The default value is 30 seconds. If this
	// PrometheusQueryLanguageCondition was generated from a Prometheus
	// alerting rule, then this value should be taken from the enclosing
	// rule group.
	EvaluationInterval *string `json:"evaluationInterval,omitempty" tf:"evaluation_interval,omitempty"`

	// Labels to add to or overwrite in the PromQL query result. Label names
	// must be valid.
	// Label values can be templatized by using variables. The only available
	// variable names are the names of the labels in the PromQL result, including
	// "name" and "value". "labels" may be empty. This field is intended to be
	// used for organizing and identifying the AlertPolicy
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	Query *string `json:"query,omitempty" tf:"query,omitempty"`

	// The rule group name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	RuleGroup *string `json:"ruleGroup,omitempty" tf:"rule_group,omitempty"`
}

type ConditionPrometheusQueryLanguageParameters struct {

	// The alerting rule name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	// +kubebuilder:validation:Optional
	AlertRule *string `json:"alertRule,omitempty" tf:"alert_rule,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// How often this rule should be evaluated. Must be a positive multiple
	// of 30 seconds or missing. The default value is 30 seconds. If this
	// PrometheusQueryLanguageCondition was generated from a Prometheus
	// alerting rule, then this value should be taken from the enclosing
	// rule group.
	// +kubebuilder:validation:Optional
	EvaluationInterval *string `json:"evaluationInterval" tf:"evaluation_interval,omitempty"`

	// Labels to add to or overwrite in the PromQL query result. Label names
	// must be valid.
	// Label values can be templatized by using variables. The only available
	// variable names are the names of the labels in the PromQL result, including
	// "name" and "value". "labels" may be empty. This field is intended to be
	// used for organizing and identifying the AlertPolicy
	// +kubebuilder:validation:Optional
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	// +kubebuilder:validation:Optional
	Query *string `json:"query" tf:"query,omitempty"`

	// The rule group name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	// +kubebuilder:validation:Optional
	RuleGroup *string `json:"ruleGroup,omitempty" tf:"rule_group,omitempty"`
}

type ConditionThresholdAggregationsInitParameters struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type ConditionThresholdAggregationsObservation struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type ConditionThresholdAggregationsParameters struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	// +kubebuilder:validation:Optional
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	// +kubebuilder:validation:Optional
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	// +kubebuilder:validation:Optional
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	// +kubebuilder:validation:Optional
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type ConditionThresholdInitParameters struct {

	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	Aggregations []ConditionThresholdAggregationsInitParameters `json:"aggregations,omitempty" tf:"aggregations,omitempty"`

	// The comparison to apply between the time
	// series (indicated by filter and aggregation)
	// and the threshold (indicated by
	// threshold_value). The comparison is applied
	// on each time series, with the time series on
	// the left-hand side and the threshold on the
	// right-hand side. Only COMPARISON_LT and
	// COMPARISON_GT are supported currently.
	// Possible values are: COMPARISON_GT, COMPARISON_GE, COMPARISON_LT, COMPARISON_LE, COMPARISON_EQ, COMPARISON_NE.
	Comparison *string `json:"comparison,omitempty" tf:"comparison,omitempty"`

	// Specifies the alignment of data points in
	// individual time series selected by
	// denominatorFilter as well as how to combine
	// the retrieved time series together (such as
	// when aggregating multiple streams on each
	// resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).When
	// computing ratios, the aggregations and
	// denominator_aggregations fields must use the
	// same alignment period and produce time
	// series that have the same periodicity and
	// labels.This field is similar to the one in
	// the MetricService.ListTimeSeries request. It
	// is advisable to use the ListTimeSeries
	// method when debugging this field.
	// Structure is documented below.
	DenominatorAggregations []DenominatorAggregationsInitParameters `json:"denominatorAggregations,omitempty" tf:"denominator_aggregations,omitempty"`

	// A filter that identifies a time series that
	// should be used as the denominator of a ratio
	// that will be compared with the threshold. If
	// a denominator_filter is specified, the time
	// series specified by the filter field will be
	// used as the numerator.The filter is similar
	// to the one that is specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	DenominatorFilter *string `json:"denominatorFilter,omitempty" tf:"denominator_filter,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	EvaluationMissingData *string `json:"evaluationMissingData,omitempty" tf:"evaluation_missing_data,omitempty"`

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// When this field is present, the MetricThreshold
	// condition forecasts whether the time series is
	// predicted to violate the threshold within the
	// forecastHorizon. When this field is not set, the
	// MetricThreshold tests the current value of the
	// timeseries against the threshold.
	// Structure is documented below.
	ForecastOptions []ForecastOptionsInitParameters `json:"forecastOptions,omitempty" tf:"forecast_options,omitempty"`

	// A value against which to compare the time
	// series.
	ThresholdValue *float64 `json:"thresholdValue,omitempty" tf:"threshold_value,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	Trigger []ConditionThresholdTriggerInitParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionThresholdObservation struct {

	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	Aggregations []ConditionThresholdAggregationsObservation `json:"aggregations,omitempty" tf:"aggregations,omitempty"`

	// The comparison to apply between the time
	// series (indicated by filter and aggregation)
	// and the threshold (indicated by
	// threshold_value). The comparison is applied
	// on each time series, with the time series on
	// the left-hand side and the threshold on the
	// right-hand side. Only COMPARISON_LT and
	// COMPARISON_GT are supported currently.
	// Possible values are: COMPARISON_GT, COMPARISON_GE, COMPARISON_LT, COMPARISON_LE, COMPARISON_EQ, COMPARISON_NE.
	Comparison *string `json:"comparison,omitempty" tf:"comparison,omitempty"`

	// Specifies the alignment of data points in
	// individual time series selected by
	// denominatorFilter as well as how to combine
	// the retrieved time series together (such as
	// when aggregating multiple streams on each
	// resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).When
	// computing ratios, the aggregations and
	// denominator_aggregations fields must use the
	// same alignment period and produce time
	// series that have the same periodicity and
	// labels.This field is similar to the one in
	// the MetricService.ListTimeSeries request. It
	// is advisable to use the ListTimeSeries
	// method when debugging this field.
	// Structure is documented below.
	DenominatorAggregations []DenominatorAggregationsObservation `json:"denominatorAggregations,omitempty" tf:"denominator_aggregations,omitempty"`

	// A filter that identifies a time series that
	// should be used as the denominator of a ratio
	// that will be compared with the threshold. If
	// a denominator_filter is specified, the time
	// series specified by the filter field will be
	// used as the numerator.The filter is similar
	// to the one that is specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	DenominatorFilter *string `json:"denominatorFilter,omitempty" tf:"denominator_filter,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	Duration *string `json:"duration,omitempty" tf:"duration,omitempty"`

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	EvaluationMissingData *string `json:"evaluationMissingData,omitempty" tf:"evaluation_missing_data,omitempty"`

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// When this field is present, the MetricThreshold
	// condition forecasts whether the time series is
	// predicted to violate the threshold within the
	// forecastHorizon. When this field is not set, the
	// MetricThreshold tests the current value of the
	// timeseries against the threshold.
	// Structure is documented below.
	ForecastOptions []ForecastOptionsObservation `json:"forecastOptions,omitempty" tf:"forecast_options,omitempty"`

	// A value against which to compare the time
	// series.
	ThresholdValue *float64 `json:"thresholdValue,omitempty" tf:"threshold_value,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	Trigger []ConditionThresholdTriggerObservation `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionThresholdParameters struct {

	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	Aggregations []ConditionThresholdAggregationsParameters `json:"aggregations,omitempty" tf:"aggregations,omitempty"`

	// The comparison to apply between the time
	// series (indicated by filter and aggregation)
	// and the threshold (indicated by
	// threshold_value). The comparison is applied
	// on each time series, with the time series on
	// the left-hand side and the threshold on the
	// right-hand side. Only COMPARISON_LT and
	// COMPARISON_GT are supported currently.
	// Possible values are: COMPARISON_GT, COMPARISON_GE, COMPARISON_LT, COMPARISON_LE, COMPARISON_EQ, COMPARISON_NE.
	// +kubebuilder:validation:Optional
	Comparison *string `json:"comparison" tf:"comparison,omitempty"`

	// Specifies the alignment of data points in
	// individual time series selected by
	// denominatorFilter as well as how to combine
	// the retrieved time series together (such as
	// when aggregating multiple streams on each
	// resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).When
	// computing ratios, the aggregations and
	// denominator_aggregations fields must use the
	// same alignment period and produce time
	// series that have the same periodicity and
	// labels.This field is similar to the one in
	// the MetricService.ListTimeSeries request. It
	// is advisable to use the ListTimeSeries
	// method when debugging this field.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	DenominatorAggregations []DenominatorAggregationsParameters `json:"denominatorAggregations,omitempty" tf:"denominator_aggregations,omitempty"`

	// A filter that identifies a time series that
	// should be used as the denominator of a ratio
	// that will be compared with the threshold. If
	// a denominator_filter is specified, the time
	// series specified by the filter field will be
	// used as the numerator.The filter is similar
	// to the one that is specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	DenominatorFilter *string `json:"denominatorFilter,omitempty" tf:"denominator_filter,omitempty"`

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	Duration *string `json:"duration" tf:"duration,omitempty"`

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	// +kubebuilder:validation:Optional
	EvaluationMissingData *string `json:"evaluationMissingData,omitempty" tf:"evaluation_missing_data,omitempty"`

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// When this field is present, the MetricThreshold
	// condition forecasts whether the time series is
	// predicted to violate the threshold within the
	// forecastHorizon. When this field is not set, the
	// MetricThreshold tests the current value of the
	// timeseries against the threshold.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	ForecastOptions []ForecastOptionsParameters `json:"forecastOptions,omitempty" tf:"forecast_options,omitempty"`

	// A value against which to compare the time
	// series.
	// +kubebuilder:validation:Optional
	ThresholdValue *float64 `json:"thresholdValue,omitempty" tf:"threshold_value,omitempty"`

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	Trigger []ConditionThresholdTriggerParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`
}

type ConditionThresholdTriggerInitParameters struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type ConditionThresholdTriggerObservation struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type ConditionThresholdTriggerParameters struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type ConditionsInitParameters struct {

	// A condition that checks that a time series
	// continues to receive new data points.
	// Structure is documented below.
	ConditionAbsent []ConditionAbsentInitParameters `json:"conditionAbsent,omitempty" tf:"condition_absent,omitempty"`

	// A condition that checks for log messages matching given constraints.
	// If set, no other conditions can be present.
	// Structure is documented below.
	ConditionMatchedLog []ConditionMatchedLogInitParameters `json:"conditionMatchedLog,omitempty" tf:"condition_matched_log,omitempty"`

	// A Monitoring Query Language query that outputs a boolean stream
	// Structure is documented below.
	ConditionMonitoringQueryLanguage []ConditionMonitoringQueryLanguageInitParameters `json:"conditionMonitoringQueryLanguage,omitempty" tf:"condition_monitoring_query_language,omitempty"`

	// A Monitoring Query Language query that outputs a boolean stream
	// A condition type that allows alert policies to be defined using
	// Prometheus Query Language (PromQL).
	// The PrometheusQueryLanguageCondition message contains information
	// from a Prometheus alerting rule and its associated rule group.
	// Structure is documented below.
	ConditionPrometheusQueryLanguage []ConditionPrometheusQueryLanguageInitParameters `json:"conditionPrometheusQueryLanguage,omitempty" tf:"condition_prometheus_query_language,omitempty"`

	// A condition that compares a time series against a
	// threshold.
	// Structure is documented below.
	ConditionThreshold []ConditionThresholdInitParameters `json:"conditionThreshold,omitempty" tf:"condition_threshold,omitempty"`

	// A short name or phrase used to identify the
	// condition in dashboards, notifications, and
	// incidents. To avoid confusion, don't use the same
	// display name for multiple conditions in the same
	// policy.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`
}

type ConditionsObservation struct {

	// A condition that checks that a time series
	// continues to receive new data points.
	// Structure is documented below.
	ConditionAbsent []ConditionAbsentObservation `json:"conditionAbsent,omitempty" tf:"condition_absent,omitempty"`

	// A condition that checks for log messages matching given constraints.
	// If set, no other conditions can be present.
	// Structure is documented below.
	ConditionMatchedLog []ConditionMatchedLogObservation `json:"conditionMatchedLog,omitempty" tf:"condition_matched_log,omitempty"`

	// A Monitoring Query Language query that outputs a boolean stream
	// Structure is documented below.
	ConditionMonitoringQueryLanguage []ConditionMonitoringQueryLanguageObservation `json:"conditionMonitoringQueryLanguage,omitempty" tf:"condition_monitoring_query_language,omitempty"`

	// A Monitoring Query Language query that outputs a boolean stream
	// A condition type that allows alert policies to be defined using
	// Prometheus Query Language (PromQL).
	// The PrometheusQueryLanguageCondition message contains information
	// from a Prometheus alerting rule and its associated rule group.
	// Structure is documented below.
	ConditionPrometheusQueryLanguage []ConditionPrometheusQueryLanguageObservation `json:"conditionPrometheusQueryLanguage,omitempty" tf:"condition_prometheus_query_language,omitempty"`

	// A condition that compares a time series against a
	// threshold.
	// Structure is documented below.
	ConditionThreshold []ConditionThresholdObservation `json:"conditionThreshold,omitempty" tf:"condition_threshold,omitempty"`

	// A short name or phrase used to identify the
	// condition in dashboards, notifications, and
	// incidents. To avoid confusion, don't use the same
	// display name for multiple conditions in the same
	// policy.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// (Output)
	// The unique resource name for this condition.
	// Its syntax is:
	// projects/[PROJECT_ID]/alertPolicies/[POLICY_ID]/conditions/[CONDITION_ID]
	// [CONDITION_ID] is assigned by Stackdriver Monitoring when
	// the condition is created as part of a new or updated alerting
	// policy.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type ConditionsParameters struct {

	// A condition that checks that a time series
	// continues to receive new data points.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	ConditionAbsent []ConditionAbsentParameters `json:"conditionAbsent,omitempty" tf:"condition_absent,omitempty"`

	// A condition that checks for log messages matching given constraints.
	// If set, no other conditions can be present.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	ConditionMatchedLog []ConditionMatchedLogParameters `json:"conditionMatchedLog,omitempty" tf:"condition_matched_log,omitempty"`

	// A Monitoring Query Language query that outputs a boolean stream
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	ConditionMonitoringQueryLanguage []ConditionMonitoringQueryLanguageParameters `json:"conditionMonitoringQueryLanguage,omitempty" tf:"condition_monitoring_query_language,omitempty"`

	// A Monitoring Query Language query that outputs a boolean stream
	// A condition type that allows alert policies to be defined using
	// Prometheus Query Language (PromQL).
	// The PrometheusQueryLanguageCondition message contains information
	// from a Prometheus alerting rule and its associated rule group.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	ConditionPrometheusQueryLanguage []ConditionPrometheusQueryLanguageParameters `json:"conditionPrometheusQueryLanguage,omitempty" tf:"condition_prometheus_query_language,omitempty"`

	// A condition that compares a time series against a
	// threshold.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	ConditionThreshold []ConditionThresholdParameters `json:"conditionThreshold,omitempty" tf:"condition_threshold,omitempty"`

	// A short name or phrase used to identify the
	// condition in dashboards, notifications, and
	// incidents. To avoid confusion, don't use the same
	// display name for multiple conditions in the same
	// policy.
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`
}

type CreationRecordInitParameters struct {
}

type CreationRecordObservation struct {

	// (Output)
	// When the change occurred.
	MutateTime *string `json:"mutateTime,omitempty" tf:"mutate_time,omitempty"`

	// (Output)
	// The email address of the user making the change.
	MutatedBy *string `json:"mutatedBy,omitempty" tf:"mutated_by,omitempty"`
}

type CreationRecordParameters struct {
}

type DenominatorAggregationsInitParameters struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type DenominatorAggregationsObservation struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type DenominatorAggregationsParameters struct {

	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	// +kubebuilder:validation:Optional
	AlignmentPeriod *string `json:"alignmentPeriod,omitempty" tf:"alignment_period,omitempty"`

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	// +kubebuilder:validation:Optional
	CrossSeriesReducer *string `json:"crossSeriesReducer,omitempty" tf:"cross_series_reducer,omitempty"`

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	// +kubebuilder:validation:Optional
	GroupByFields []*string `json:"groupByFields,omitempty" tf:"group_by_fields,omitempty"`

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	// +kubebuilder:validation:Optional
	PerSeriesAligner *string `json:"perSeriesAligner,omitempty" tf:"per_series_aligner,omitempty"`
}

type DocumentationInitParameters struct {

	// The text of the documentation, interpreted according to mimeType.
	// The content may not exceed 8,192 Unicode characters and may not
	// exceed more than 10,240 bytes when encoded in UTF-8 format,
	// whichever is smaller.
	Content *string `json:"content,omitempty" tf:"content,omitempty"`

	// The format of the content field. Presently, only the value
	// "text/markdown" is supported.
	MimeType *string `json:"mimeType,omitempty" tf:"mime_type,omitempty"`
}

type DocumentationObservation struct {

	// The text of the documentation, interpreted according to mimeType.
	// The content may not exceed 8,192 Unicode characters and may not
	// exceed more than 10,240 bytes when encoded in UTF-8 format,
	// whichever is smaller.
	Content *string `json:"content,omitempty" tf:"content,omitempty"`

	// The format of the content field. Presently, only the value
	// "text/markdown" is supported.
	MimeType *string `json:"mimeType,omitempty" tf:"mime_type,omitempty"`
}

type DocumentationParameters struct {

	// The text of the documentation, interpreted according to mimeType.
	// The content may not exceed 8,192 Unicode characters and may not
	// exceed more than 10,240 bytes when encoded in UTF-8 format,
	// whichever is smaller.
	// +kubebuilder:validation:Optional
	Content *string `json:"content,omitempty" tf:"content,omitempty"`

	// The format of the content field. Presently, only the value
	// "text/markdown" is supported.
	// +kubebuilder:validation:Optional
	MimeType *string `json:"mimeType,omitempty" tf:"mime_type,omitempty"`
}

type ForecastOptionsInitParameters struct {

	// The length of time into the future to forecast
	// whether a timeseries will violate the threshold.
	// If the predicted value is found to violate the
	// threshold, and the violation is observed in all
	// forecasts made for the Configured duration,
	// then the timeseries is considered to be failing.
	ForecastHorizon *string `json:"forecastHorizon,omitempty" tf:"forecast_horizon,omitempty"`
}

type ForecastOptionsObservation struct {

	// The length of time into the future to forecast
	// whether a timeseries will violate the threshold.
	// If the predicted value is found to violate the
	// threshold, and the violation is observed in all
	// forecasts made for the Configured duration,
	// then the timeseries is considered to be failing.
	ForecastHorizon *string `json:"forecastHorizon,omitempty" tf:"forecast_horizon,omitempty"`
}

type ForecastOptionsParameters struct {

	// The length of time into the future to forecast
	// whether a timeseries will violate the threshold.
	// If the predicted value is found to violate the
	// threshold, and the violation is observed in all
	// forecasts made for the Configured duration,
	// then the timeseries is considered to be failing.
	// +kubebuilder:validation:Optional
	ForecastHorizon *string `json:"forecastHorizon" tf:"forecast_horizon,omitempty"`
}

type NotificationChannelStrategyInitParameters struct {

	// The notification channels that these settings apply to. Each of these
	// correspond to the name field in one of the NotificationChannel objects
	// referenced in the notification_channels field of this AlertPolicy. The format is
	// projects/[PROJECT_ID_OR_NUMBER]/notificationChannels/[CHANNEL_ID]
	NotificationChannelNames []*string `json:"notificationChannelNames,omitempty" tf:"notification_channel_names,omitempty"`

	// The frequency at which to send reminder notifications for open incidents.
	RenotifyInterval *string `json:"renotifyInterval,omitempty" tf:"renotify_interval,omitempty"`
}

type NotificationChannelStrategyObservation struct {

	// The notification channels that these settings apply to. Each of these
	// correspond to the name field in one of the NotificationChannel objects
	// referenced in the notification_channels field of this AlertPolicy. The format is
	// projects/[PROJECT_ID_OR_NUMBER]/notificationChannels/[CHANNEL_ID]
	NotificationChannelNames []*string `json:"notificationChannelNames,omitempty" tf:"notification_channel_names,omitempty"`

	// The frequency at which to send reminder notifications for open incidents.
	RenotifyInterval *string `json:"renotifyInterval,omitempty" tf:"renotify_interval,omitempty"`
}

type NotificationChannelStrategyParameters struct {

	// The notification channels that these settings apply to. Each of these
	// correspond to the name field in one of the NotificationChannel objects
	// referenced in the notification_channels field of this AlertPolicy. The format is
	// projects/[PROJECT_ID_OR_NUMBER]/notificationChannels/[CHANNEL_ID]
	// +kubebuilder:validation:Optional
	NotificationChannelNames []*string `json:"notificationChannelNames,omitempty" tf:"notification_channel_names,omitempty"`

	// The frequency at which to send reminder notifications for open incidents.
	// +kubebuilder:validation:Optional
	RenotifyInterval *string `json:"renotifyInterval,omitempty" tf:"renotify_interval,omitempty"`
}

type NotificationRateLimitInitParameters struct {

	// Not more than one notification per period.
	Period *string `json:"period,omitempty" tf:"period,omitempty"`
}

type NotificationRateLimitObservation struct {

	// Not more than one notification per period.
	Period *string `json:"period,omitempty" tf:"period,omitempty"`
}

type NotificationRateLimitParameters struct {

	// Not more than one notification per period.
	// +kubebuilder:validation:Optional
	Period *string `json:"period,omitempty" tf:"period,omitempty"`
}

type TriggerInitParameters struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type TriggerObservation struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

type TriggerParameters struct {

	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	Percent *float64 `json:"percent,omitempty" tf:"percent,omitempty"`
}

// AlertPolicySpec defines the desired state of AlertPolicy
type AlertPolicySpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     AlertPolicyParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider AlertPolicyInitParameters `json:"initProvider,omitempty"`
}

// AlertPolicyStatus defines the observed state of AlertPolicy.
type AlertPolicyStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        AlertPolicyObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// AlertPolicy is the Schema for the AlertPolicys API. A description of the conditions under which some aspect of your system is considered to be "unhealthy" and the ways to notify people or services about this state.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,gcp}
type AlertPolicy struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.combiner) || (has(self.initProvider) && has(self.initProvider.combiner))",message="spec.forProvider.combiner is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.conditions) || (has(self.initProvider) && has(self.initProvider.conditions))",message="spec.forProvider.conditions is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.displayName) || (has(self.initProvider) && has(self.initProvider.displayName))",message="spec.forProvider.displayName is a required parameter"
	Spec   AlertPolicySpec   `json:"spec"`
	Status AlertPolicyStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// AlertPolicyList contains a list of AlertPolicys
type AlertPolicyList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []AlertPolicy `json:"items"`
}

// Repository type metadata.
var (
	AlertPolicy_Kind             = "AlertPolicy"
	AlertPolicy_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: AlertPolicy_Kind}.String()
	AlertPolicy_KindAPIVersion   = AlertPolicy_Kind + "." + CRDGroupVersion.String()
	AlertPolicy_GroupVersionKind = CRDGroupVersion.WithKind(AlertPolicy_Kind)
)

func init() {
	SchemeBuilder.Register(&AlertPolicy{}, &AlertPolicyList{})
}
