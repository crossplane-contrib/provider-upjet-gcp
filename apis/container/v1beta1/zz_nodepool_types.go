// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1beta1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type NetworkConfigNetworkPerformanceConfigInitParameters struct {
	TotalEgressBandwidthTier *string `json:"totalEgressBandwidthTier,omitempty" tf:"total_egress_bandwidth_tier,omitempty"`
}

type NetworkConfigNetworkPerformanceConfigObservation struct {
	TotalEgressBandwidthTier *string `json:"totalEgressBandwidthTier,omitempty" tf:"total_egress_bandwidth_tier,omitempty"`
}

type NetworkConfigNetworkPerformanceConfigParameters struct {

	// +kubebuilder:validation:Optional
	TotalEgressBandwidthTier *string `json:"totalEgressBandwidthTier" tf:"total_egress_bandwidth_tier,omitempty"`
}

type NodeConfigGuestAcceleratorGpuDriverInstallationConfigInitParameters struct {

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	GpuDriverVersion *string `json:"gpuDriverVersion,omitempty" tf:"gpu_driver_version"`
}

type NodeConfigGuestAcceleratorGpuDriverInstallationConfigObservation struct {

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	GpuDriverVersion *string `json:"gpuDriverVersion,omitempty" tf:"gpu_driver_version,omitempty"`
}

type NodeConfigGuestAcceleratorGpuDriverInstallationConfigParameters struct {

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	// +kubebuilder:validation:Optional
	GpuDriverVersion *string `json:"gpuDriverVersion,omitempty" tf:"gpu_driver_version"`
}

type NodeConfigGuestAcceleratorGpuSharingConfigInitParameters struct {
	GpuSharingStrategy *string `json:"gpuSharingStrategy,omitempty" tf:"gpu_sharing_strategy"`

	MaxSharedClientsPerGpu *float64 `json:"maxSharedClientsPerGpu,omitempty" tf:"max_shared_clients_per_gpu"`
}

type NodeConfigGuestAcceleratorGpuSharingConfigObservation struct {
	GpuSharingStrategy *string `json:"gpuSharingStrategy,omitempty" tf:"gpu_sharing_strategy,omitempty"`

	MaxSharedClientsPerGpu *float64 `json:"maxSharedClientsPerGpu,omitempty" tf:"max_shared_clients_per_gpu,omitempty"`
}

type NodeConfigGuestAcceleratorGpuSharingConfigParameters struct {

	// +kubebuilder:validation:Optional
	GpuSharingStrategy *string `json:"gpuSharingStrategy,omitempty" tf:"gpu_sharing_strategy"`

	// +kubebuilder:validation:Optional
	MaxSharedClientsPerGpu *float64 `json:"maxSharedClientsPerGpu,omitempty" tf:"max_shared_clients_per_gpu"`
}

type NodeConfigSoleTenantConfigNodeAffinityInitParameters struct {
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	Operator *string `json:"operator,omitempty" tf:"operator,omitempty"`

	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type NodeConfigSoleTenantConfigNodeAffinityObservation struct {
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	Operator *string `json:"operator,omitempty" tf:"operator,omitempty"`

	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type NodeConfigSoleTenantConfigNodeAffinityParameters struct {

	// +kubebuilder:validation:Optional
	Key *string `json:"key" tf:"key,omitempty"`

	// +kubebuilder:validation:Optional
	Operator *string `json:"operator" tf:"operator,omitempty"`

	// +kubebuilder:validation:Optional
	Values []*string `json:"values" tf:"values,omitempty"`
}

type NodePoolAutoscalingInitParameters struct {

	// Location policy specifies the algorithm used when
	// scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
	LocationPolicy *string `json:"locationPolicy,omitempty" tf:"location_policy,omitempty"`

	// Maximum number of nodes per zone in the NodePool.
	// Must be >= min_node_count. Cannot be used with total limits.
	MaxNodeCount *float64 `json:"maxNodeCount,omitempty" tf:"max_node_count,omitempty"`

	// Minimum number of nodes per zone in the NodePool.
	// Must be >=0 and <= max_node_count. Cannot be used with total limits.
	MinNodeCount *float64 `json:"minNodeCount,omitempty" tf:"min_node_count,omitempty"`

	// Total maximum number of nodes in the NodePool.
	// Must be >= total_min_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	TotalMaxNodeCount *float64 `json:"totalMaxNodeCount,omitempty" tf:"total_max_node_count,omitempty"`

	// Total minimum number of nodes in the NodePool.
	// Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	TotalMinNodeCount *float64 `json:"totalMinNodeCount,omitempty" tf:"total_min_node_count,omitempty"`
}

type NodePoolAutoscalingObservation struct {

	// Location policy specifies the algorithm used when
	// scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
	LocationPolicy *string `json:"locationPolicy,omitempty" tf:"location_policy,omitempty"`

	// Maximum number of nodes per zone in the NodePool.
	// Must be >= min_node_count. Cannot be used with total limits.
	MaxNodeCount *float64 `json:"maxNodeCount,omitempty" tf:"max_node_count,omitempty"`

	// Minimum number of nodes per zone in the NodePool.
	// Must be >=0 and <= max_node_count. Cannot be used with total limits.
	MinNodeCount *float64 `json:"minNodeCount,omitempty" tf:"min_node_count,omitempty"`

	// Total maximum number of nodes in the NodePool.
	// Must be >= total_min_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	TotalMaxNodeCount *float64 `json:"totalMaxNodeCount,omitempty" tf:"total_max_node_count,omitempty"`

	// Total minimum number of nodes in the NodePool.
	// Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	TotalMinNodeCount *float64 `json:"totalMinNodeCount,omitempty" tf:"total_min_node_count,omitempty"`
}

type NodePoolAutoscalingParameters struct {

	// Location policy specifies the algorithm used when
	// scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
	// +kubebuilder:validation:Optional
	LocationPolicy *string `json:"locationPolicy,omitempty" tf:"location_policy,omitempty"`

	// Maximum number of nodes per zone in the NodePool.
	// Must be >= min_node_count. Cannot be used with total limits.
	// +kubebuilder:validation:Optional
	MaxNodeCount *float64 `json:"maxNodeCount,omitempty" tf:"max_node_count,omitempty"`

	// Minimum number of nodes per zone in the NodePool.
	// Must be >=0 and <= max_node_count. Cannot be used with total limits.
	// +kubebuilder:validation:Optional
	MinNodeCount *float64 `json:"minNodeCount,omitempty" tf:"min_node_count,omitempty"`

	// Total maximum number of nodes in the NodePool.
	// Must be >= total_min_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	// +kubebuilder:validation:Optional
	TotalMaxNodeCount *float64 `json:"totalMaxNodeCount,omitempty" tf:"total_max_node_count,omitempty"`

	// Total minimum number of nodes in the NodePool.
	// Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	// +kubebuilder:validation:Optional
	TotalMinNodeCount *float64 `json:"totalMinNodeCount,omitempty" tf:"total_min_node_count,omitempty"`
}

type NodePoolInitParameters_2 struct {

	// Configuration required by cluster autoscaler to adjust
	// the size of the node pool to the current cluster usage. Structure is documented below.
	Autoscaling []NodePoolAutoscalingInitParameters `json:"autoscaling,omitempty" tf:"autoscaling,omitempty"`

	// The initial number of nodes for the pool. In
	// regional or multi-zonal clusters, this is the number of nodes per zone. Changing
	// this will force recreation of the resource.  If you don't
	// need this value, don't set it.  If you do need it, you can use a lifecycle block to
	// ignore subsequent changes to this field.
	InitialNodeCount *float64 `json:"initialNodeCount,omitempty" tf:"initial_node_count,omitempty"`

	// Node management configuration, wherein auto-repair and
	// auto-upgrade is configured. Structure is documented below.
	Management []NodePoolManagementInitParameters_2 `json:"management,omitempty" tf:"management,omitempty"`

	// The maximum number of pods per node in this node pool.
	// Note that this does not work on node pools which are "route-based" - that is, node
	// pools belonging to clusters that do not have IP Aliasing enabled.
	// See the official documentation
	// for more information.
	MaxPodsPerNode *float64 `json:"maxPodsPerNode,omitempty" tf:"max_pods_per_node,omitempty"`

	// The network configuration of the pool. Such as
	// configuration for Adding Pod IP address ranges) to the node pool. Or enabling private nodes. Structure is
	// documented below
	NetworkConfig []NodePoolNetworkConfigInitParameters `json:"networkConfig,omitempty" tf:"network_config,omitempty"`

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	// +listType=map
	// +listMapKey=index
	NodeConfig []NodePoolNodeConfigInitParameters_2 `json:"nodeConfig,omitempty" tf:"node_config,omitempty"`

	// The number of nodes per instance group. This field can be used to
	// update the number of nodes per instance group but should not be used alongside autoscaling.
	NodeCount *float64 `json:"nodeCount,omitempty" tf:"node_count,omitempty"`

	// The list of zones in which the node pool's nodes should be located. Nodes must
	// be in the region of their regional cluster or in the same region as their
	// cluster's zone for zonal clusters. If unspecified, the cluster-level
	// node_locations will be used.
	// +listType=set
	NodeLocations []*string `json:"nodeLocations,omitempty" tf:"node_locations,omitempty"`

	// Specifies a custom placement policy for the
	// nodes.
	PlacementPolicy []NodePoolPlacementPolicyInitParameters `json:"placementPolicy,omitempty" tf:"placement_policy,omitempty"`

	// The ID of the project in which to create the node pool. If blank,
	// the provider-configured project will be used.
	Project *string `json:"project,omitempty" tf:"project,omitempty"`

	// Specify node upgrade settings to change how GKE upgrades nodes.
	// The maximum number of nodes upgraded simultaneously is limited to 20. Structure is documented below.
	UpgradeSettings []NodePoolUpgradeSettingsInitParameters_2 `json:"upgradeSettings,omitempty" tf:"upgrade_settings,omitempty"`

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`
}

type NodePoolManagementInitParameters_2 struct {

	// Whether the nodes will be automatically repaired. Enabled by default.
	AutoRepair *bool `json:"autoRepair,omitempty" tf:"auto_repair,omitempty"`

	// Whether the nodes will be automatically upgraded. Enabled by default.
	AutoUpgrade *bool `json:"autoUpgrade,omitempty" tf:"auto_upgrade,omitempty"`
}

type NodePoolManagementObservation_2 struct {

	// Whether the nodes will be automatically repaired. Enabled by default.
	AutoRepair *bool `json:"autoRepair,omitempty" tf:"auto_repair,omitempty"`

	// Whether the nodes will be automatically upgraded. Enabled by default.
	AutoUpgrade *bool `json:"autoUpgrade,omitempty" tf:"auto_upgrade,omitempty"`
}

type NodePoolManagementParameters_2 struct {

	// Whether the nodes will be automatically repaired. Enabled by default.
	// +kubebuilder:validation:Optional
	AutoRepair *bool `json:"autoRepair,omitempty" tf:"auto_repair,omitempty"`

	// Whether the nodes will be automatically upgraded. Enabled by default.
	// +kubebuilder:validation:Optional
	AutoUpgrade *bool `json:"autoUpgrade,omitempty" tf:"auto_upgrade,omitempty"`
}

type NodePoolNetworkConfigInitParameters struct {

	// Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
	CreatePodRange *bool `json:"createPodRange,omitempty" tf:"create_pod_range,omitempty"`

	// Whether nodes have internal IP addresses only.
	EnablePrivateNodes *bool `json:"enablePrivateNodes,omitempty" tf:"enable_private_nodes,omitempty"`

	NetworkPerformanceConfig []NetworkConfigNetworkPerformanceConfigInitParameters `json:"networkPerformanceConfig,omitempty" tf:"network_performance_config,omitempty"`

	PodCidrOverprovisionConfig []NodePoolNetworkConfigPodCidrOverprovisionConfigInitParameters `json:"podCidrOverprovisionConfig,omitempty" tf:"pod_cidr_overprovision_config,omitempty"`

	// The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
	PodIPv4CidrBlock *string `json:"podIpv4CidrBlock,omitempty" tf:"pod_ipv4_cidr_block,omitempty"`

	// The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
	PodRange *string `json:"podRange,omitempty" tf:"pod_range,omitempty"`
}

type NodePoolNetworkConfigObservation struct {

	// Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
	CreatePodRange *bool `json:"createPodRange,omitempty" tf:"create_pod_range,omitempty"`

	// Whether nodes have internal IP addresses only.
	EnablePrivateNodes *bool `json:"enablePrivateNodes,omitempty" tf:"enable_private_nodes,omitempty"`

	NetworkPerformanceConfig []NetworkConfigNetworkPerformanceConfigObservation `json:"networkPerformanceConfig,omitempty" tf:"network_performance_config,omitempty"`

	PodCidrOverprovisionConfig []NodePoolNetworkConfigPodCidrOverprovisionConfigObservation `json:"podCidrOverprovisionConfig,omitempty" tf:"pod_cidr_overprovision_config,omitempty"`

	// The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
	PodIPv4CidrBlock *string `json:"podIpv4CidrBlock,omitempty" tf:"pod_ipv4_cidr_block,omitempty"`

	// The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
	PodRange *string `json:"podRange,omitempty" tf:"pod_range,omitempty"`
}

type NodePoolNetworkConfigParameters struct {

	// Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
	// +kubebuilder:validation:Optional
	CreatePodRange *bool `json:"createPodRange,omitempty" tf:"create_pod_range,omitempty"`

	// Whether nodes have internal IP addresses only.
	// +kubebuilder:validation:Optional
	EnablePrivateNodes *bool `json:"enablePrivateNodes,omitempty" tf:"enable_private_nodes,omitempty"`

	// +kubebuilder:validation:Optional
	NetworkPerformanceConfig []NetworkConfigNetworkPerformanceConfigParameters `json:"networkPerformanceConfig,omitempty" tf:"network_performance_config,omitempty"`

	// +kubebuilder:validation:Optional
	PodCidrOverprovisionConfig []NodePoolNetworkConfigPodCidrOverprovisionConfigParameters `json:"podCidrOverprovisionConfig,omitempty" tf:"pod_cidr_overprovision_config,omitempty"`

	// The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
	// +kubebuilder:validation:Optional
	PodIPv4CidrBlock *string `json:"podIpv4CidrBlock,omitempty" tf:"pod_ipv4_cidr_block,omitempty"`

	// The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
	// +kubebuilder:validation:Optional
	PodRange *string `json:"podRange,omitempty" tf:"pod_range,omitempty"`
}

type NodePoolNetworkConfigPodCidrOverprovisionConfigInitParameters struct {
	Disabled *bool `json:"disabled,omitempty" tf:"disabled,omitempty"`
}

type NodePoolNetworkConfigPodCidrOverprovisionConfigObservation struct {
	Disabled *bool `json:"disabled,omitempty" tf:"disabled,omitempty"`
}

type NodePoolNetworkConfigPodCidrOverprovisionConfigParameters struct {

	// +kubebuilder:validation:Optional
	Disabled *bool `json:"disabled" tf:"disabled,omitempty"`
}

type NodePoolNodeConfigAdvancedMachineFeaturesInitParameters struct {
	ThreadsPerCore *float64 `json:"threadsPerCore,omitempty" tf:"threads_per_core,omitempty"`
}

type NodePoolNodeConfigAdvancedMachineFeaturesObservation struct {
	ThreadsPerCore *float64 `json:"threadsPerCore,omitempty" tf:"threads_per_core,omitempty"`
}

type NodePoolNodeConfigAdvancedMachineFeaturesParameters struct {

	// +kubebuilder:validation:Optional
	ThreadsPerCore *float64 `json:"threadsPerCore" tf:"threads_per_core,omitempty"`
}

type NodePoolNodeConfigConfidentialNodesInitParameters_2 struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigConfidentialNodesObservation_2 struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigConfidentialNodesParameters_2 struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigEffectiveTaintsInitParameters struct {
}

type NodePoolNodeConfigEffectiveTaintsObservation struct {
	Effect *string `json:"effect,omitempty" tf:"effect,omitempty"`

	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type NodePoolNodeConfigEffectiveTaintsParameters struct {
}

type NodePoolNodeConfigEphemeralStorageLocalSsdConfigInitParameters struct {
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`
}

type NodePoolNodeConfigEphemeralStorageLocalSsdConfigObservation struct {
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`
}

type NodePoolNodeConfigEphemeralStorageLocalSsdConfigParameters struct {

	// +kubebuilder:validation:Optional
	LocalSsdCount *float64 `json:"localSsdCount" tf:"local_ssd_count,omitempty"`
}

type NodePoolNodeConfigFastSocketInitParameters struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigFastSocketObservation struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigFastSocketParameters struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigGcfsConfigInitParameters struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigGcfsConfigObservation struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigGcfsConfigParameters struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigGuestAcceleratorInitParameters struct {
	Count *float64 `json:"count,omitempty" tf:"count"`

	GpuDriverInstallationConfig []NodeConfigGuestAcceleratorGpuDriverInstallationConfigInitParameters `json:"gpuDriverInstallationConfig,omitempty" tf:"gpu_driver_installation_config"`

	GpuPartitionSize *string `json:"gpuPartitionSize,omitempty" tf:"gpu_partition_size"`

	GpuSharingConfig []NodeConfigGuestAcceleratorGpuSharingConfigInitParameters `json:"gpuSharingConfig,omitempty" tf:"gpu_sharing_config"`

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	Type *string `json:"type,omitempty" tf:"type"`
}

type NodePoolNodeConfigGuestAcceleratorObservation struct {
	Count *float64 `json:"count,omitempty" tf:"count,omitempty"`

	GpuDriverInstallationConfig []NodeConfigGuestAcceleratorGpuDriverInstallationConfigObservation `json:"gpuDriverInstallationConfig,omitempty" tf:"gpu_driver_installation_config,omitempty"`

	GpuPartitionSize *string `json:"gpuPartitionSize,omitempty" tf:"gpu_partition_size,omitempty"`

	GpuSharingConfig []NodeConfigGuestAcceleratorGpuSharingConfigObservation `json:"gpuSharingConfig,omitempty" tf:"gpu_sharing_config,omitempty"`

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type NodePoolNodeConfigGuestAcceleratorParameters struct {

	// +kubebuilder:validation:Optional
	Count *float64 `json:"count,omitempty" tf:"count"`

	// +kubebuilder:validation:Optional
	GpuDriverInstallationConfig []NodeConfigGuestAcceleratorGpuDriverInstallationConfigParameters `json:"gpuDriverInstallationConfig,omitempty" tf:"gpu_driver_installation_config"`

	// +kubebuilder:validation:Optional
	GpuPartitionSize *string `json:"gpuPartitionSize,omitempty" tf:"gpu_partition_size"`

	// +kubebuilder:validation:Optional
	GpuSharingConfig []NodeConfigGuestAcceleratorGpuSharingConfigParameters `json:"gpuSharingConfig,omitempty" tf:"gpu_sharing_config"`

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	// +kubebuilder:validation:Optional
	Type *string `json:"type,omitempty" tf:"type"`
}

type NodePoolNodeConfigGvnicInitParameters struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigGvnicObservation struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigGvnicParameters struct {

	// Makes nodes obtainable through the ProvisioningRequest API exclusively.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`
}

type NodePoolNodeConfigHostMaintenancePolicyInitParameters struct {
	MaintenanceInterval *string `json:"maintenanceInterval,omitempty" tf:"maintenance_interval,omitempty"`
}

type NodePoolNodeConfigHostMaintenancePolicyObservation struct {
	MaintenanceInterval *string `json:"maintenanceInterval,omitempty" tf:"maintenance_interval,omitempty"`
}

type NodePoolNodeConfigHostMaintenancePolicyParameters struct {

	// +kubebuilder:validation:Optional
	MaintenanceInterval *string `json:"maintenanceInterval" tf:"maintenance_interval,omitempty"`
}

type NodePoolNodeConfigInitParameters_2 struct {
	AdvancedMachineFeatures []NodePoolNodeConfigAdvancedMachineFeaturesInitParameters `json:"advancedMachineFeatures,omitempty" tf:"advanced_machine_features,omitempty"`

	BootDiskKMSKey *string `json:"bootDiskKmsKey,omitempty" tf:"boot_disk_kms_key,omitempty"`

	// Configuration for Confidential Nodes feature. Structure is documented below.
	ConfidentialNodes []NodePoolNodeConfigConfidentialNodesInitParameters_2 `json:"confidentialNodes,omitempty" tf:"confidential_nodes,omitempty"`

	DiskSizeGb *float64 `json:"diskSizeGb,omitempty" tf:"disk_size_gb,omitempty"`

	DiskType *string `json:"diskType,omitempty" tf:"disk_type,omitempty"`

	EnableConfidentialStorage *bool `json:"enableConfidentialStorage,omitempty" tf:"enable_confidential_storage,omitempty"`

	EphemeralStorageLocalSsdConfig []NodePoolNodeConfigEphemeralStorageLocalSsdConfigInitParameters `json:"ephemeralStorageLocalSsdConfig,omitempty" tf:"ephemeral_storage_local_ssd_config,omitempty"`

	FastSocket []NodePoolNodeConfigFastSocketInitParameters `json:"fastSocket,omitempty" tf:"fast_socket,omitempty"`

	GcfsConfig []NodePoolNodeConfigGcfsConfigInitParameters `json:"gcfsConfig,omitempty" tf:"gcfs_config,omitempty"`

	GuestAccelerator []NodePoolNodeConfigGuestAcceleratorInitParameters `json:"guestAccelerator,omitempty" tf:"guest_accelerator,omitempty"`

	Gvnic []NodePoolNodeConfigGvnicInitParameters `json:"gvnic,omitempty" tf:"gvnic,omitempty"`

	HostMaintenancePolicy []NodePoolNodeConfigHostMaintenancePolicyInitParameters `json:"hostMaintenancePolicy,omitempty" tf:"host_maintenance_policy,omitempty"`

	ImageType *string `json:"imageType,omitempty" tf:"image_type,omitempty"`

	// This is an injected field with a default value for being able to merge items of the parent object list.
	// +kubebuilder:default:="0"
	Index *string `json:"index,omitempty" tf:"-"`

	KubeletConfig []NodePoolNodeConfigKubeletConfigInitParameters `json:"kubeletConfig,omitempty" tf:"kubelet_config,omitempty"`

	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	LinuxNodeConfig []NodePoolNodeConfigLinuxNodeConfigInitParameters `json:"linuxNodeConfig,omitempty" tf:"linux_node_config,omitempty"`

	LocalNvmeSsdBlockConfig []NodePoolNodeConfigLocalNvmeSsdBlockConfigInitParameters `json:"localNvmeSsdBlockConfig,omitempty" tf:"local_nvme_ssd_block_config,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	LoggingVariant *string `json:"loggingVariant,omitempty" tf:"logging_variant,omitempty"`

	MachineType *string `json:"machineType,omitempty" tf:"machine_type,omitempty"`

	// +mapType=granular
	Metadata map[string]*string `json:"metadata,omitempty" tf:"metadata,omitempty"`

	MinCPUPlatform *string `json:"minCpuPlatform,omitempty" tf:"min_cpu_platform,omitempty"`

	NodeGroup *string `json:"nodeGroup,omitempty" tf:"node_group,omitempty"`

	// +listType=set
	OAuthScopes []*string `json:"oauthScopes,omitempty" tf:"oauth_scopes,omitempty"`

	Preemptible *bool `json:"preemptible,omitempty" tf:"preemptible,omitempty"`

	ReservationAffinity []NodePoolNodeConfigReservationAffinityInitParameters `json:"reservationAffinity,omitempty" tf:"reservation_affinity,omitempty"`

	// +mapType=granular
	ResourceLabels map[string]*string `json:"resourceLabels,omitempty" tf:"resource_labels,omitempty"`

	// +mapType=granular
	ResourceManagerTags map[string]*string `json:"resourceManagerTags,omitempty" tf:"resource_manager_tags,omitempty"`

	// +crossplane:generate:reference:type=github.com/upbound/provider-gcp/apis/cloudplatform/v1beta1.ServiceAccount
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractParamPath("email",true)
	ServiceAccount *string `json:"serviceAccount,omitempty" tf:"service_account,omitempty"`

	// Reference to a ServiceAccount in cloudplatform to populate serviceAccount.
	// +kubebuilder:validation:Optional
	ServiceAccountRef *v1.Reference `json:"serviceAccountRef,omitempty" tf:"-"`

	// Selector for a ServiceAccount in cloudplatform to populate serviceAccount.
	// +kubebuilder:validation:Optional
	ServiceAccountSelector *v1.Selector `json:"serviceAccountSelector,omitempty" tf:"-"`

	ShieldedInstanceConfig []NodePoolNodeConfigShieldedInstanceConfigInitParameters_2 `json:"shieldedInstanceConfig,omitempty" tf:"shielded_instance_config,omitempty"`

	SoleTenantConfig []NodePoolNodeConfigSoleTenantConfigInitParameters `json:"soleTenantConfig,omitempty" tf:"sole_tenant_config,omitempty"`

	Spot *bool `json:"spot,omitempty" tf:"spot,omitempty"`

	Tags []*string `json:"tags,omitempty" tf:"tags,omitempty"`

	Taint []NodePoolNodeConfigTaintInitParameters `json:"taint,omitempty" tf:"taint,omitempty"`

	WorkloadMetadataConfig []NodePoolNodeConfigWorkloadMetadataConfigInitParameters `json:"workloadMetadataConfig,omitempty" tf:"workload_metadata_config,omitempty"`
}

type NodePoolNodeConfigKubeletConfigInitParameters struct {
	CPUCfsQuota *bool `json:"cpuCfsQuota,omitempty" tf:"cpu_cfs_quota,omitempty"`

	CPUCfsQuotaPeriod *string `json:"cpuCfsQuotaPeriod,omitempty" tf:"cpu_cfs_quota_period,omitempty"`

	CPUManagerPolicy *string `json:"cpuManagerPolicy,omitempty" tf:"cpu_manager_policy,omitempty"`

	PodPidsLimit *float64 `json:"podPidsLimit,omitempty" tf:"pod_pids_limit,omitempty"`
}

type NodePoolNodeConfigKubeletConfigObservation struct {
	CPUCfsQuota *bool `json:"cpuCfsQuota,omitempty" tf:"cpu_cfs_quota,omitempty"`

	CPUCfsQuotaPeriod *string `json:"cpuCfsQuotaPeriod,omitempty" tf:"cpu_cfs_quota_period,omitempty"`

	CPUManagerPolicy *string `json:"cpuManagerPolicy,omitempty" tf:"cpu_manager_policy,omitempty"`

	PodPidsLimit *float64 `json:"podPidsLimit,omitempty" tf:"pod_pids_limit,omitempty"`
}

type NodePoolNodeConfigKubeletConfigParameters struct {

	// +kubebuilder:validation:Optional
	CPUCfsQuota *bool `json:"cpuCfsQuota,omitempty" tf:"cpu_cfs_quota,omitempty"`

	// +kubebuilder:validation:Optional
	CPUCfsQuotaPeriod *string `json:"cpuCfsQuotaPeriod,omitempty" tf:"cpu_cfs_quota_period,omitempty"`

	// +kubebuilder:validation:Optional
	CPUManagerPolicy *string `json:"cpuManagerPolicy" tf:"cpu_manager_policy,omitempty"`

	// +kubebuilder:validation:Optional
	PodPidsLimit *float64 `json:"podPidsLimit,omitempty" tf:"pod_pids_limit,omitempty"`
}

type NodePoolNodeConfigLinuxNodeConfigInitParameters struct {
	CgroupMode *string `json:"cgroupMode,omitempty" tf:"cgroup_mode,omitempty"`

	// +mapType=granular
	Sysctls map[string]*string `json:"sysctls,omitempty" tf:"sysctls,omitempty"`
}

type NodePoolNodeConfigLinuxNodeConfigObservation struct {
	CgroupMode *string `json:"cgroupMode,omitempty" tf:"cgroup_mode,omitempty"`

	// +mapType=granular
	Sysctls map[string]*string `json:"sysctls,omitempty" tf:"sysctls,omitempty"`
}

type NodePoolNodeConfigLinuxNodeConfigParameters struct {

	// +kubebuilder:validation:Optional
	CgroupMode *string `json:"cgroupMode,omitempty" tf:"cgroup_mode,omitempty"`

	// +kubebuilder:validation:Optional
	// +mapType=granular
	Sysctls map[string]*string `json:"sysctls,omitempty" tf:"sysctls,omitempty"`
}

type NodePoolNodeConfigLocalNvmeSsdBlockConfigInitParameters struct {
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`
}

type NodePoolNodeConfigLocalNvmeSsdBlockConfigObservation struct {
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`
}

type NodePoolNodeConfigLocalNvmeSsdBlockConfigParameters struct {

	// +kubebuilder:validation:Optional
	LocalSsdCount *float64 `json:"localSsdCount" tf:"local_ssd_count,omitempty"`
}

type NodePoolNodeConfigObservation_2 struct {
	AdvancedMachineFeatures []NodePoolNodeConfigAdvancedMachineFeaturesObservation `json:"advancedMachineFeatures,omitempty" tf:"advanced_machine_features,omitempty"`

	BootDiskKMSKey *string `json:"bootDiskKmsKey,omitempty" tf:"boot_disk_kms_key,omitempty"`

	// Configuration for Confidential Nodes feature. Structure is documented below.
	ConfidentialNodes []NodePoolNodeConfigConfidentialNodesObservation_2 `json:"confidentialNodes,omitempty" tf:"confidential_nodes,omitempty"`

	DiskSizeGb *float64 `json:"diskSizeGb,omitempty" tf:"disk_size_gb,omitempty"`

	DiskType *string `json:"diskType,omitempty" tf:"disk_type,omitempty"`

	EffectiveTaints []NodePoolNodeConfigEffectiveTaintsObservation `json:"effectiveTaints,omitempty" tf:"effective_taints,omitempty"`

	EnableConfidentialStorage *bool `json:"enableConfidentialStorage,omitempty" tf:"enable_confidential_storage,omitempty"`

	EphemeralStorageLocalSsdConfig []NodePoolNodeConfigEphemeralStorageLocalSsdConfigObservation `json:"ephemeralStorageLocalSsdConfig,omitempty" tf:"ephemeral_storage_local_ssd_config,omitempty"`

	FastSocket []NodePoolNodeConfigFastSocketObservation `json:"fastSocket,omitempty" tf:"fast_socket,omitempty"`

	GcfsConfig []NodePoolNodeConfigGcfsConfigObservation `json:"gcfsConfig,omitempty" tf:"gcfs_config,omitempty"`

	GuestAccelerator []NodePoolNodeConfigGuestAcceleratorObservation `json:"guestAccelerator,omitempty" tf:"guest_accelerator,omitempty"`

	Gvnic []NodePoolNodeConfigGvnicObservation `json:"gvnic,omitempty" tf:"gvnic,omitempty"`

	HostMaintenancePolicy []NodePoolNodeConfigHostMaintenancePolicyObservation `json:"hostMaintenancePolicy,omitempty" tf:"host_maintenance_policy,omitempty"`

	ImageType *string `json:"imageType,omitempty" tf:"image_type,omitempty"`

	// This is an injected field with a default value for being able to merge items of the parent object list.
	// +kubebuilder:default:="0"
	Index *string `json:"index,omitempty" tf:"-"`

	KubeletConfig []NodePoolNodeConfigKubeletConfigObservation `json:"kubeletConfig,omitempty" tf:"kubelet_config,omitempty"`

	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	LinuxNodeConfig []NodePoolNodeConfigLinuxNodeConfigObservation `json:"linuxNodeConfig,omitempty" tf:"linux_node_config,omitempty"`

	LocalNvmeSsdBlockConfig []NodePoolNodeConfigLocalNvmeSsdBlockConfigObservation `json:"localNvmeSsdBlockConfig,omitempty" tf:"local_nvme_ssd_block_config,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	LoggingVariant *string `json:"loggingVariant,omitempty" tf:"logging_variant,omitempty"`

	MachineType *string `json:"machineType,omitempty" tf:"machine_type,omitempty"`

	// +mapType=granular
	Metadata map[string]*string `json:"metadata,omitempty" tf:"metadata,omitempty"`

	MinCPUPlatform *string `json:"minCpuPlatform,omitempty" tf:"min_cpu_platform,omitempty"`

	NodeGroup *string `json:"nodeGroup,omitempty" tf:"node_group,omitempty"`

	// +listType=set
	OAuthScopes []*string `json:"oauthScopes,omitempty" tf:"oauth_scopes,omitempty"`

	Preemptible *bool `json:"preemptible,omitempty" tf:"preemptible,omitempty"`

	ReservationAffinity []NodePoolNodeConfigReservationAffinityObservation `json:"reservationAffinity,omitempty" tf:"reservation_affinity,omitempty"`

	// +mapType=granular
	ResourceLabels map[string]*string `json:"resourceLabels,omitempty" tf:"resource_labels,omitempty"`

	// +mapType=granular
	ResourceManagerTags map[string]*string `json:"resourceManagerTags,omitempty" tf:"resource_manager_tags,omitempty"`

	ServiceAccount *string `json:"serviceAccount,omitempty" tf:"service_account,omitempty"`

	ShieldedInstanceConfig []NodePoolNodeConfigShieldedInstanceConfigObservation_2 `json:"shieldedInstanceConfig,omitempty" tf:"shielded_instance_config,omitempty"`

	SoleTenantConfig []NodePoolNodeConfigSoleTenantConfigObservation `json:"soleTenantConfig,omitempty" tf:"sole_tenant_config,omitempty"`

	Spot *bool `json:"spot,omitempty" tf:"spot,omitempty"`

	Tags []*string `json:"tags,omitempty" tf:"tags,omitempty"`

	Taint []NodePoolNodeConfigTaintObservation `json:"taint,omitempty" tf:"taint,omitempty"`

	WorkloadMetadataConfig []NodePoolNodeConfigWorkloadMetadataConfigObservation `json:"workloadMetadataConfig,omitempty" tf:"workload_metadata_config,omitempty"`
}

type NodePoolNodeConfigParameters_2 struct {

	// +kubebuilder:validation:Optional
	AdvancedMachineFeatures []NodePoolNodeConfigAdvancedMachineFeaturesParameters `json:"advancedMachineFeatures,omitempty" tf:"advanced_machine_features,omitempty"`

	// +kubebuilder:validation:Optional
	BootDiskKMSKey *string `json:"bootDiskKmsKey,omitempty" tf:"boot_disk_kms_key,omitempty"`

	// Configuration for Confidential Nodes feature. Structure is documented below.
	// +kubebuilder:validation:Optional
	ConfidentialNodes []NodePoolNodeConfigConfidentialNodesParameters_2 `json:"confidentialNodes,omitempty" tf:"confidential_nodes,omitempty"`

	// +kubebuilder:validation:Optional
	DiskSizeGb *float64 `json:"diskSizeGb,omitempty" tf:"disk_size_gb,omitempty"`

	// +kubebuilder:validation:Optional
	DiskType *string `json:"diskType,omitempty" tf:"disk_type,omitempty"`

	// +kubebuilder:validation:Optional
	EnableConfidentialStorage *bool `json:"enableConfidentialStorage,omitempty" tf:"enable_confidential_storage,omitempty"`

	// +kubebuilder:validation:Optional
	EphemeralStorageLocalSsdConfig []NodePoolNodeConfigEphemeralStorageLocalSsdConfigParameters `json:"ephemeralStorageLocalSsdConfig,omitempty" tf:"ephemeral_storage_local_ssd_config,omitempty"`

	// +kubebuilder:validation:Optional
	FastSocket []NodePoolNodeConfigFastSocketParameters `json:"fastSocket,omitempty" tf:"fast_socket,omitempty"`

	// +kubebuilder:validation:Optional
	GcfsConfig []NodePoolNodeConfigGcfsConfigParameters `json:"gcfsConfig,omitempty" tf:"gcfs_config,omitempty"`

	// +kubebuilder:validation:Optional
	GuestAccelerator []NodePoolNodeConfigGuestAcceleratorParameters `json:"guestAccelerator,omitempty" tf:"guest_accelerator,omitempty"`

	// +kubebuilder:validation:Optional
	Gvnic []NodePoolNodeConfigGvnicParameters `json:"gvnic,omitempty" tf:"gvnic,omitempty"`

	// +kubebuilder:validation:Optional
	HostMaintenancePolicy []NodePoolNodeConfigHostMaintenancePolicyParameters `json:"hostMaintenancePolicy,omitempty" tf:"host_maintenance_policy,omitempty"`

	// +kubebuilder:validation:Optional
	ImageType *string `json:"imageType,omitempty" tf:"image_type,omitempty"`

	// This is an injected field with a default value for being able to merge items of the parent object list.
	// +kubebuilder:validation:Optional
	// +kubebuilder:default:="0"
	Index *string `json:"index" tf:"-"`

	// +kubebuilder:validation:Optional
	KubeletConfig []NodePoolNodeConfigKubeletConfigParameters `json:"kubeletConfig,omitempty" tf:"kubelet_config,omitempty"`

	// +kubebuilder:validation:Optional
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	// +kubebuilder:validation:Optional
	LinuxNodeConfig []NodePoolNodeConfigLinuxNodeConfigParameters `json:"linuxNodeConfig,omitempty" tf:"linux_node_config,omitempty"`

	// +kubebuilder:validation:Optional
	LocalNvmeSsdBlockConfig []NodePoolNodeConfigLocalNvmeSsdBlockConfigParameters `json:"localNvmeSsdBlockConfig,omitempty" tf:"local_nvme_ssd_block_config,omitempty"`

	// +kubebuilder:validation:Optional
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	// +kubebuilder:validation:Optional
	LoggingVariant *string `json:"loggingVariant,omitempty" tf:"logging_variant,omitempty"`

	// +kubebuilder:validation:Optional
	MachineType *string `json:"machineType,omitempty" tf:"machine_type,omitempty"`

	// +kubebuilder:validation:Optional
	// +mapType=granular
	Metadata map[string]*string `json:"metadata,omitempty" tf:"metadata,omitempty"`

	// +kubebuilder:validation:Optional
	MinCPUPlatform *string `json:"minCpuPlatform,omitempty" tf:"min_cpu_platform,omitempty"`

	// +kubebuilder:validation:Optional
	NodeGroup *string `json:"nodeGroup,omitempty" tf:"node_group,omitempty"`

	// +kubebuilder:validation:Optional
	// +listType=set
	OAuthScopes []*string `json:"oauthScopes,omitempty" tf:"oauth_scopes,omitempty"`

	// +kubebuilder:validation:Optional
	Preemptible *bool `json:"preemptible,omitempty" tf:"preemptible,omitempty"`

	// +kubebuilder:validation:Optional
	ReservationAffinity []NodePoolNodeConfigReservationAffinityParameters `json:"reservationAffinity,omitempty" tf:"reservation_affinity,omitempty"`

	// +kubebuilder:validation:Optional
	// +mapType=granular
	ResourceLabels map[string]*string `json:"resourceLabels,omitempty" tf:"resource_labels,omitempty"`

	// +kubebuilder:validation:Optional
	// +mapType=granular
	ResourceManagerTags map[string]*string `json:"resourceManagerTags,omitempty" tf:"resource_manager_tags,omitempty"`

	// +crossplane:generate:reference:type=github.com/upbound/provider-gcp/apis/cloudplatform/v1beta1.ServiceAccount
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractParamPath("email",true)
	// +kubebuilder:validation:Optional
	ServiceAccount *string `json:"serviceAccount,omitempty" tf:"service_account,omitempty"`

	// Reference to a ServiceAccount in cloudplatform to populate serviceAccount.
	// +kubebuilder:validation:Optional
	ServiceAccountRef *v1.Reference `json:"serviceAccountRef,omitempty" tf:"-"`

	// Selector for a ServiceAccount in cloudplatform to populate serviceAccount.
	// +kubebuilder:validation:Optional
	ServiceAccountSelector *v1.Selector `json:"serviceAccountSelector,omitempty" tf:"-"`

	// +kubebuilder:validation:Optional
	ShieldedInstanceConfig []NodePoolNodeConfigShieldedInstanceConfigParameters_2 `json:"shieldedInstanceConfig,omitempty" tf:"shielded_instance_config,omitempty"`

	// +kubebuilder:validation:Optional
	SoleTenantConfig []NodePoolNodeConfigSoleTenantConfigParameters `json:"soleTenantConfig,omitempty" tf:"sole_tenant_config,omitempty"`

	// +kubebuilder:validation:Optional
	Spot *bool `json:"spot,omitempty" tf:"spot,omitempty"`

	// +kubebuilder:validation:Optional
	Tags []*string `json:"tags,omitempty" tf:"tags,omitempty"`

	// +kubebuilder:validation:Optional
	Taint []NodePoolNodeConfigTaintParameters `json:"taint,omitempty" tf:"taint,omitempty"`

	// +kubebuilder:validation:Optional
	WorkloadMetadataConfig []NodePoolNodeConfigWorkloadMetadataConfigParameters `json:"workloadMetadataConfig,omitempty" tf:"workload_metadata_config,omitempty"`
}

type NodePoolNodeConfigReservationAffinityInitParameters struct {
	ConsumeReservationType *string `json:"consumeReservationType,omitempty" tf:"consume_reservation_type,omitempty"`

	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// +listType=set
	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type NodePoolNodeConfigReservationAffinityObservation struct {
	ConsumeReservationType *string `json:"consumeReservationType,omitempty" tf:"consume_reservation_type,omitempty"`

	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// +listType=set
	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type NodePoolNodeConfigReservationAffinityParameters struct {

	// +kubebuilder:validation:Optional
	ConsumeReservationType *string `json:"consumeReservationType" tf:"consume_reservation_type,omitempty"`

	// +kubebuilder:validation:Optional
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// +kubebuilder:validation:Optional
	// +listType=set
	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type NodePoolNodeConfigShieldedInstanceConfigInitParameters_2 struct {
	EnableIntegrityMonitoring *bool `json:"enableIntegrityMonitoring,omitempty" tf:"enable_integrity_monitoring,omitempty"`

	EnableSecureBoot *bool `json:"enableSecureBoot,omitempty" tf:"enable_secure_boot,omitempty"`
}

type NodePoolNodeConfigShieldedInstanceConfigObservation_2 struct {
	EnableIntegrityMonitoring *bool `json:"enableIntegrityMonitoring,omitempty" tf:"enable_integrity_monitoring,omitempty"`

	EnableSecureBoot *bool `json:"enableSecureBoot,omitempty" tf:"enable_secure_boot,omitempty"`
}

type NodePoolNodeConfigShieldedInstanceConfigParameters_2 struct {

	// +kubebuilder:validation:Optional
	EnableIntegrityMonitoring *bool `json:"enableIntegrityMonitoring,omitempty" tf:"enable_integrity_monitoring,omitempty"`

	// +kubebuilder:validation:Optional
	EnableSecureBoot *bool `json:"enableSecureBoot,omitempty" tf:"enable_secure_boot,omitempty"`
}

type NodePoolNodeConfigSoleTenantConfigInitParameters struct {
	NodeAffinity []NodeConfigSoleTenantConfigNodeAffinityInitParameters `json:"nodeAffinity,omitempty" tf:"node_affinity,omitempty"`
}

type NodePoolNodeConfigSoleTenantConfigObservation struct {
	NodeAffinity []NodeConfigSoleTenantConfigNodeAffinityObservation `json:"nodeAffinity,omitempty" tf:"node_affinity,omitempty"`
}

type NodePoolNodeConfigSoleTenantConfigParameters struct {

	// +kubebuilder:validation:Optional
	NodeAffinity []NodeConfigSoleTenantConfigNodeAffinityParameters `json:"nodeAffinity" tf:"node_affinity,omitempty"`
}

type NodePoolNodeConfigTaintInitParameters struct {
	Effect *string `json:"effect,omitempty" tf:"effect,omitempty"`

	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type NodePoolNodeConfigTaintObservation struct {
	Effect *string `json:"effect,omitempty" tf:"effect,omitempty"`

	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type NodePoolNodeConfigTaintParameters struct {

	// +kubebuilder:validation:Optional
	Effect *string `json:"effect" tf:"effect,omitempty"`

	// +kubebuilder:validation:Optional
	Key *string `json:"key" tf:"key,omitempty"`

	// +kubebuilder:validation:Optional
	Value *string `json:"value" tf:"value,omitempty"`
}

type NodePoolNodeConfigWorkloadMetadataConfigInitParameters struct {
	Mode *string `json:"mode,omitempty" tf:"mode,omitempty"`
}

type NodePoolNodeConfigWorkloadMetadataConfigObservation struct {
	Mode *string `json:"mode,omitempty" tf:"mode,omitempty"`
}

type NodePoolNodeConfigWorkloadMetadataConfigParameters struct {

	// +kubebuilder:validation:Optional
	Mode *string `json:"mode" tf:"mode,omitempty"`
}

type NodePoolObservation_2 struct {

	// Configuration required by cluster autoscaler to adjust
	// the size of the node pool to the current cluster usage. Structure is documented below.
	Autoscaling []NodePoolAutoscalingObservation `json:"autoscaling,omitempty" tf:"autoscaling,omitempty"`

	// The cluster to create the node pool for. Cluster must be present in location provided for clusters. May be specified in the format projects/{{project}}/locations/{{location}}/clusters/{{cluster}} or as just the name of the cluster.
	Cluster *string `json:"cluster,omitempty" tf:"cluster,omitempty"`

	// an identifier for the resource with format {{project}}/{{location}}/{{cluster}}/{{name}}
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// The initial number of nodes for the pool. In
	// regional or multi-zonal clusters, this is the number of nodes per zone. Changing
	// this will force recreation of the resource.  If you don't
	// need this value, don't set it.  If you do need it, you can use a lifecycle block to
	// ignore subsequent changes to this field.
	InitialNodeCount *float64 `json:"initialNodeCount,omitempty" tf:"initial_node_count,omitempty"`

	// The resource URLs of the managed instance groups associated with this node pool.
	InstanceGroupUrls []*string `json:"instanceGroupUrls,omitempty" tf:"instance_group_urls,omitempty"`

	// The location (region or zone) of the cluster.
	Location *string `json:"location,omitempty" tf:"location,omitempty"`

	// List of instance group URLs which have been assigned to this node pool.
	ManagedInstanceGroupUrls []*string `json:"managedInstanceGroupUrls,omitempty" tf:"managed_instance_group_urls,omitempty"`

	// Node management configuration, wherein auto-repair and
	// auto-upgrade is configured. Structure is documented below.
	Management []NodePoolManagementObservation_2 `json:"management,omitempty" tf:"management,omitempty"`

	// The maximum number of pods per node in this node pool.
	// Note that this does not work on node pools which are "route-based" - that is, node
	// pools belonging to clusters that do not have IP Aliasing enabled.
	// See the official documentation
	// for more information.
	MaxPodsPerNode *float64 `json:"maxPodsPerNode,omitempty" tf:"max_pods_per_node,omitempty"`

	// The network configuration of the pool. Such as
	// configuration for Adding Pod IP address ranges) to the node pool. Or enabling private nodes. Structure is
	// documented below
	NetworkConfig []NodePoolNetworkConfigObservation `json:"networkConfig,omitempty" tf:"network_config,omitempty"`

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	// +listType=map
	// +listMapKey=index
	NodeConfig []NodePoolNodeConfigObservation_2 `json:"nodeConfig,omitempty" tf:"node_config,omitempty"`

	// The number of nodes per instance group. This field can be used to
	// update the number of nodes per instance group but should not be used alongside autoscaling.
	NodeCount *float64 `json:"nodeCount,omitempty" tf:"node_count,omitempty"`

	// The list of zones in which the node pool's nodes should be located. Nodes must
	// be in the region of their regional cluster or in the same region as their
	// cluster's zone for zonal clusters. If unspecified, the cluster-level
	// node_locations will be used.
	// +listType=set
	NodeLocations []*string `json:"nodeLocations,omitempty" tf:"node_locations,omitempty"`

	Operation *string `json:"operation,omitempty" tf:"operation,omitempty"`

	// Specifies a custom placement policy for the
	// nodes.
	PlacementPolicy []NodePoolPlacementPolicyObservation `json:"placementPolicy,omitempty" tf:"placement_policy,omitempty"`

	// The ID of the project in which to create the node pool. If blank,
	// the provider-configured project will be used.
	Project *string `json:"project,omitempty" tf:"project,omitempty"`

	// Specify node upgrade settings to change how GKE upgrades nodes.
	// The maximum number of nodes upgraded simultaneously is limited to 20. Structure is documented below.
	UpgradeSettings []NodePoolUpgradeSettingsObservation_2 `json:"upgradeSettings,omitempty" tf:"upgrade_settings,omitempty"`

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`
}

type NodePoolParameters_2 struct {

	// Configuration required by cluster autoscaler to adjust
	// the size of the node pool to the current cluster usage. Structure is documented below.
	// +kubebuilder:validation:Optional
	Autoscaling []NodePoolAutoscalingParameters `json:"autoscaling,omitempty" tf:"autoscaling,omitempty"`

	// The cluster to create the node pool for. Cluster must be present in location provided for clusters. May be specified in the format projects/{{project}}/locations/{{location}}/clusters/{{cluster}} or as just the name of the cluster.
	// +crossplane:generate:reference:type=Cluster
	// +crossplane:generate:reference:extractor=github.com/upbound/provider-gcp/config/common.ExtractResourceID()
	// +kubebuilder:validation:Optional
	Cluster *string `json:"cluster,omitempty" tf:"cluster,omitempty"`

	// Reference to a Cluster to populate cluster.
	// +kubebuilder:validation:Optional
	ClusterRef *v1.Reference `json:"clusterRef,omitempty" tf:"-"`

	// Selector for a Cluster to populate cluster.
	// +kubebuilder:validation:Optional
	ClusterSelector *v1.Selector `json:"clusterSelector,omitempty" tf:"-"`

	// The initial number of nodes for the pool. In
	// regional or multi-zonal clusters, this is the number of nodes per zone. Changing
	// this will force recreation of the resource.  If you don't
	// need this value, don't set it.  If you do need it, you can use a lifecycle block to
	// ignore subsequent changes to this field.
	// +kubebuilder:validation:Optional
	InitialNodeCount *float64 `json:"initialNodeCount,omitempty" tf:"initial_node_count,omitempty"`

	// The location (region or zone) of the cluster.
	// +kubebuilder:validation:Optional
	Location *string `json:"location,omitempty" tf:"location,omitempty"`

	// Node management configuration, wherein auto-repair and
	// auto-upgrade is configured. Structure is documented below.
	// +kubebuilder:validation:Optional
	Management []NodePoolManagementParameters_2 `json:"management,omitempty" tf:"management,omitempty"`

	// The maximum number of pods per node in this node pool.
	// Note that this does not work on node pools which are "route-based" - that is, node
	// pools belonging to clusters that do not have IP Aliasing enabled.
	// See the official documentation
	// for more information.
	// +kubebuilder:validation:Optional
	MaxPodsPerNode *float64 `json:"maxPodsPerNode,omitempty" tf:"max_pods_per_node,omitempty"`

	// The network configuration of the pool. Such as
	// configuration for Adding Pod IP address ranges) to the node pool. Or enabling private nodes. Structure is
	// documented below
	// +kubebuilder:validation:Optional
	NetworkConfig []NodePoolNetworkConfigParameters `json:"networkConfig,omitempty" tf:"network_config,omitempty"`

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	// +kubebuilder:validation:Optional
	// +listType=map
	// +listMapKey=index
	NodeConfig []NodePoolNodeConfigParameters_2 `json:"nodeConfig,omitempty" tf:"node_config,omitempty"`

	// The number of nodes per instance group. This field can be used to
	// update the number of nodes per instance group but should not be used alongside autoscaling.
	// +kubebuilder:validation:Optional
	NodeCount *float64 `json:"nodeCount,omitempty" tf:"node_count,omitempty"`

	// The list of zones in which the node pool's nodes should be located. Nodes must
	// be in the region of their regional cluster or in the same region as their
	// cluster's zone for zonal clusters. If unspecified, the cluster-level
	// node_locations will be used.
	// +kubebuilder:validation:Optional
	// +listType=set
	NodeLocations []*string `json:"nodeLocations,omitempty" tf:"node_locations,omitempty"`

	// Specifies a custom placement policy for the
	// nodes.
	// +kubebuilder:validation:Optional
	PlacementPolicy []NodePoolPlacementPolicyParameters `json:"placementPolicy,omitempty" tf:"placement_policy,omitempty"`

	// The ID of the project in which to create the node pool. If blank,
	// the provider-configured project will be used.
	// +kubebuilder:validation:Optional
	Project *string `json:"project,omitempty" tf:"project,omitempty"`

	// Specify node upgrade settings to change how GKE upgrades nodes.
	// The maximum number of nodes upgraded simultaneously is limited to 20. Structure is documented below.
	// +kubebuilder:validation:Optional
	UpgradeSettings []NodePoolUpgradeSettingsParameters_2 `json:"upgradeSettings,omitempty" tf:"upgrade_settings,omitempty"`

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	// +kubebuilder:validation:Optional
	Version *string `json:"version,omitempty" tf:"version,omitempty"`
}

type NodePoolPlacementPolicyInitParameters struct {

	// If set, refers to the name of a custom resource policy supplied by the user.
	// The resource policy must be in the same project and region as the node pool.
	// If not found, InvalidArgument error is returned.
	PolicyName *string `json:"policyName,omitempty" tf:"policy_name,omitempty"`

	// The TPU placement topology for pod slice node pool.
	TpuTopology *string `json:"tpuTopology,omitempty" tf:"tpu_topology,omitempty"`

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type NodePoolPlacementPolicyObservation struct {

	// If set, refers to the name of a custom resource policy supplied by the user.
	// The resource policy must be in the same project and region as the node pool.
	// If not found, InvalidArgument error is returned.
	PolicyName *string `json:"policyName,omitempty" tf:"policy_name,omitempty"`

	// The TPU placement topology for pod slice node pool.
	TpuTopology *string `json:"tpuTopology,omitempty" tf:"tpu_topology,omitempty"`

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type NodePoolPlacementPolicyParameters struct {

	// If set, refers to the name of a custom resource policy supplied by the user.
	// The resource policy must be in the same project and region as the node pool.
	// If not found, InvalidArgument error is returned.
	// +kubebuilder:validation:Optional
	PolicyName *string `json:"policyName,omitempty" tf:"policy_name,omitempty"`

	// The TPU placement topology for pod slice node pool.
	// +kubebuilder:validation:Optional
	TpuTopology *string `json:"tpuTopology,omitempty" tf:"tpu_topology,omitempty"`

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type NodePoolUpgradeSettingsBlueGreenSettingsInitParameters struct {

	// Time needed after draining the entire blue pool.
	// After this period, the blue pool will be cleaned up.
	NodePoolSoakDuration *string `json:"nodePoolSoakDuration,omitempty" tf:"node_pool_soak_duration,omitempty"`

	// Specifies the standard policy settings for blue-green upgrades.
	StandardRolloutPolicy []UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyInitParameters `json:"standardRolloutPolicy,omitempty" tf:"standard_rollout_policy,omitempty"`
}

type NodePoolUpgradeSettingsBlueGreenSettingsObservation struct {

	// Time needed after draining the entire blue pool.
	// After this period, the blue pool will be cleaned up.
	NodePoolSoakDuration *string `json:"nodePoolSoakDuration,omitempty" tf:"node_pool_soak_duration,omitempty"`

	// Specifies the standard policy settings for blue-green upgrades.
	StandardRolloutPolicy []UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyObservation `json:"standardRolloutPolicy,omitempty" tf:"standard_rollout_policy,omitempty"`
}

type NodePoolUpgradeSettingsBlueGreenSettingsParameters struct {

	// Time needed after draining the entire blue pool.
	// After this period, the blue pool will be cleaned up.
	// +kubebuilder:validation:Optional
	NodePoolSoakDuration *string `json:"nodePoolSoakDuration,omitempty" tf:"node_pool_soak_duration,omitempty"`

	// Specifies the standard policy settings for blue-green upgrades.
	// +kubebuilder:validation:Optional
	StandardRolloutPolicy []UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyParameters `json:"standardRolloutPolicy" tf:"standard_rollout_policy,omitempty"`
}

type NodePoolUpgradeSettingsInitParameters_2 struct {

	// The settings to adjust blue green upgrades.
	// Structure is documented below
	BlueGreenSettings []NodePoolUpgradeSettingsBlueGreenSettingsInitParameters `json:"blueGreenSettings,omitempty" tf:"blue_green_settings,omitempty"`

	// The number of additional nodes that can be added to the node pool during
	// an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously.
	// Can be set to 0 or greater.
	MaxSurge *float64 `json:"maxSurge,omitempty" tf:"max_surge,omitempty"`

	// The number of nodes that can be simultaneously unavailable during
	// an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in
	// parallel. Can be set to 0 or greater.
	MaxUnavailable *float64 `json:"maxUnavailable,omitempty" tf:"max_unavailable,omitempty"`

	// (Default SURGE) The upgrade stragey to be used for upgrading the nodes.
	Strategy *string `json:"strategy,omitempty" tf:"strategy,omitempty"`
}

type NodePoolUpgradeSettingsObservation_2 struct {

	// The settings to adjust blue green upgrades.
	// Structure is documented below
	BlueGreenSettings []NodePoolUpgradeSettingsBlueGreenSettingsObservation `json:"blueGreenSettings,omitempty" tf:"blue_green_settings,omitempty"`

	// The number of additional nodes that can be added to the node pool during
	// an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously.
	// Can be set to 0 or greater.
	MaxSurge *float64 `json:"maxSurge,omitempty" tf:"max_surge,omitempty"`

	// The number of nodes that can be simultaneously unavailable during
	// an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in
	// parallel. Can be set to 0 or greater.
	MaxUnavailable *float64 `json:"maxUnavailable,omitempty" tf:"max_unavailable,omitempty"`

	// (Default SURGE) The upgrade stragey to be used for upgrading the nodes.
	Strategy *string `json:"strategy,omitempty" tf:"strategy,omitempty"`
}

type NodePoolUpgradeSettingsParameters_2 struct {

	// The settings to adjust blue green upgrades.
	// Structure is documented below
	// +kubebuilder:validation:Optional
	BlueGreenSettings []NodePoolUpgradeSettingsBlueGreenSettingsParameters `json:"blueGreenSettings,omitempty" tf:"blue_green_settings,omitempty"`

	// The number of additional nodes that can be added to the node pool during
	// an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously.
	// Can be set to 0 or greater.
	// +kubebuilder:validation:Optional
	MaxSurge *float64 `json:"maxSurge,omitempty" tf:"max_surge,omitempty"`

	// The number of nodes that can be simultaneously unavailable during
	// an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in
	// parallel. Can be set to 0 or greater.
	// +kubebuilder:validation:Optional
	MaxUnavailable *float64 `json:"maxUnavailable,omitempty" tf:"max_unavailable,omitempty"`

	// (Default SURGE) The upgrade stragey to be used for upgrading the nodes.
	// +kubebuilder:validation:Optional
	Strategy *string `json:"strategy,omitempty" tf:"strategy,omitempty"`
}

type UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyInitParameters struct {

	// Number of blue nodes to drain in a batch.
	BatchNodeCount *float64 `json:"batchNodeCount,omitempty" tf:"batch_node_count,omitempty"`

	// Percentage of the blue pool nodes to drain in a batch.
	BatchPercentage *float64 `json:"batchPercentage,omitempty" tf:"batch_percentage,omitempty"`

	// (Optionial) Soak time after each batch gets drained.
	BatchSoakDuration *string `json:"batchSoakDuration,omitempty" tf:"batch_soak_duration,omitempty"`
}

type UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyObservation struct {

	// Number of blue nodes to drain in a batch.
	BatchNodeCount *float64 `json:"batchNodeCount,omitempty" tf:"batch_node_count,omitempty"`

	// Percentage of the blue pool nodes to drain in a batch.
	BatchPercentage *float64 `json:"batchPercentage,omitempty" tf:"batch_percentage,omitempty"`

	// (Optionial) Soak time after each batch gets drained.
	BatchSoakDuration *string `json:"batchSoakDuration,omitempty" tf:"batch_soak_duration,omitempty"`
}

type UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyParameters struct {

	// Number of blue nodes to drain in a batch.
	// +kubebuilder:validation:Optional
	BatchNodeCount *float64 `json:"batchNodeCount,omitempty" tf:"batch_node_count,omitempty"`

	// Percentage of the blue pool nodes to drain in a batch.
	// +kubebuilder:validation:Optional
	BatchPercentage *float64 `json:"batchPercentage,omitempty" tf:"batch_percentage,omitempty"`

	// (Optionial) Soak time after each batch gets drained.
	// +kubebuilder:validation:Optional
	BatchSoakDuration *string `json:"batchSoakDuration,omitempty" tf:"batch_soak_duration,omitempty"`
}

// NodePoolSpec defines the desired state of NodePool
type NodePoolSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     NodePoolParameters_2 `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider NodePoolInitParameters_2 `json:"initProvider,omitempty"`
}

// NodePoolStatus defines the observed state of NodePool.
type NodePoolStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        NodePoolObservation_2 `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// NodePool is the Schema for the NodePools API. Manages a GKE NodePool resource.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,gcp}
type NodePool struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	Spec              NodePoolSpec   `json:"spec"`
	Status            NodePoolStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// NodePoolList contains a list of NodePools
type NodePoolList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []NodePool `json:"items"`
}

// Repository type metadata.
var (
	NodePool_Kind             = "NodePool"
	NodePool_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: NodePool_Kind}.String()
	NodePool_KindAPIVersion   = NodePool_Kind + "." + CRDGroupVersion.String()
	NodePool_GroupVersionKind = CRDGroupVersion.WithKind(NodePool_Kind)
)

func init() {
	SchemeBuilder.Register(&NodePool{}, &NodePoolList{})
}
