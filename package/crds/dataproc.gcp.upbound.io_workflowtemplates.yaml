---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.12.1
  name: workflowtemplates.dataproc.gcp.upbound.io
spec:
  group: dataproc.gcp.upbound.io
  names:
    categories:
    - crossplane
    - managed
    - gcp
    kind: WorkflowTemplate
    listKind: WorkflowTemplateList
    plural: workflowtemplates
    singular: workflowtemplate
  scope: Cluster
  versions:
  - additionalPrinterColumns:
    - jsonPath: .status.conditions[?(@.type=='Ready')].status
      name: READY
      type: string
    - jsonPath: .status.conditions[?(@.type=='Synced')].status
      name: SYNCED
      type: string
    - jsonPath: .metadata.annotations.crossplane\.io/external-name
      name: EXTERNAL-NAME
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: AGE
      type: date
    name: v1beta1
    schema:
      openAPIV3Schema:
        description: WorkflowTemplate is the Schema for the WorkflowTemplates API.
          A Workflow Template is a reusable workflow configuration.
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: WorkflowTemplateSpec defines the desired state of WorkflowTemplate
            properties:
              deletionPolicy:
                default: Delete
                description: 'DeletionPolicy specifies what will happen to the underlying
                  external when this managed resource is deleted - either "Delete"
                  or "Orphan" the external resource. This field is planned to be deprecated
                  in favor of the ManagementPolicies field in a future release. Currently,
                  both could be set independently and non-default values would be
                  honored if the feature flag is enabled. See the design doc for more
                  information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223'
                enum:
                - Orphan
                - Delete
                type: string
              forProvider:
                properties:
                  dagTimeout:
                    description: (Beta only) Optional. Timeout duration for the DAG
                      of jobs. You can use "s", "m", "h", and "d" suffixes for second,
                      minute, hour, and day duration values, respectively. The timeout
                      duration must be from 10 minutes ("10m") to 24 hours ("24h"
                      or "1d"). The timer begins when the first job is submitted.
                      If the workflow is running at the end of the timeout period,
                      any remaining jobs are cancelled, the workflow is ended, and
                      if the workflow was running on a (/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
                      the cluster is deleted.
                    type: string
                  jobs:
                    description: Required. The Directed Acyclic Graph of Jobs to submit.
                    items:
                      properties:
                        hadoopJob:
                          description: Optional. Job is a Hadoop job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainClass:
                                description: The name of the driver's main class.
                                  The jar file that contains the class must be in
                                  the default CLASSPATH or specified in jar_file_uris.
                                type: string
                              mainJarFileUri:
                                description: The HCFS URI of the jar file that contains
                                  the main class.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        hiveJob:
                          description: Optional. Job is a Hive job.
                          items:
                            properties:
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        labels:
                          additionalProperties:
                            type: string
                          description: 'Optional. The labels to associate with this
                            job. Label keys must be between 1 and 63 characters long,
                            and must conform to the following regular expression:
                            {0,63} No more than 32 labels can be associated with a
                            given job.'
                          type: object
                        pigJob:
                          description: Optional. Job is a Pig job.
                          items:
                            properties:
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        prerequisiteStepIds:
                          description: Optional. The optional list of prerequisite
                            job step_ids. If not specified, the job will start at
                            the beginning of workflow.
                          items:
                            type: string
                          type: array
                        prestoJob:
                          description: Optional. Job is a Presto job.
                          items:
                            properties:
                              clientTags:
                                description: Optional. Presto client tags to attach
                                  to this query
                                items:
                                  type: string
                                type: array
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              outputFormat:
                                description: Optional. The format in which query output
                                  will be displayed. See the Presto documentation
                                  for supported output formats
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                            type: object
                          type: array
                        pysparkJob:
                          description: Optional. Job is a PySpark job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainPythonFileUri:
                                description: Required. The HCFS URI of the main Python
                                  file to use as the driver. Must be a .py file.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              pythonFileUris:
                                description: 'Optional. HCFS file URIs of Python files
                                  to pass to the PySpark framework. Supported file
                                  types: .py, .egg, and .zip.'
                                items:
                                  type: string
                                type: array
                            type: object
                          type: array
                        scheduling:
                          description: Optional. Job scheduling configuration.
                          items:
                            properties:
                              maxFailuresPerHour:
                                description: Optional. Maximum number of times per
                                  hour a driver may be restarted as a result of driver
                                  exiting with non-zero code before job is reported
                                  failed. A job may be reported as thrashing if driver
                                  exits with non-zero code 4 times within 10 minute
                                  window. Maximum value is 10.
                                type: number
                              maxFailuresTotal:
                                description: Optional. Maximum number of times in
                                  total a driver may be restarted as a result of driver
                                  exiting with non-zero code before job is reported
                                  failed. Maximum value is 240
                                type: number
                            type: object
                          type: array
                        sparkJob:
                          description: Optional. Job is a Spark job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainClass:
                                description: The name of the driver's main class.
                                  The jar file that contains the class must be in
                                  the default CLASSPATH or specified in jar_file_uris.
                                type: string
                              mainJarFileUri:
                                description: The HCFS URI of the jar file that contains
                                  the main class.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        sparkRJob:
                          description: Optional. Job is a SparkR job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainRFileUri:
                                description: Required. The HCFS URI of the main R
                                  file to use as the driver. Must be a .R file.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        sparkSqlJob:
                          description: Optional. Job is a SparkSql job.
                          items:
                            properties:
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        stepId:
                          description: Required. The step id. The id must be unique
                            among all jobs within the template. The step id is used
                            as prefix for job id, as job goog-dataproc-workflow-step-id
                            label, and in field from other steps. The id must contain
                            only letters (a-z, A-Z), numbers (0-9), underscores (_),
                            and hyphens (-). Cannot begin or end with underscore or
                            hyphen. Must consist of between 3 and 50 characters.
                          type: string
                      type: object
                    type: array
                  labels:
                    additionalProperties:
                      type: string
                    description: 'Optional. The labels to associate with this cluster.
                      Label keys must be between 1 and 63 characters long, and must
                      conform to the following PCRE regular expression: {0,63} No
                      more than 32 labels can be associated with a given cluster.'
                    type: object
                  location:
                    description: The location for the resource
                    type: string
                  parameters:
                    description: Optional. Template parameters whose values are substituted
                      into the template. Values for parameters must be provided when
                      the template is instantiated.
                    items:
                      properties:
                        description:
                          description: Optional. Brief description of the parameter.
                            Must not exceed 1024 characters.
                          type: string
                        fields:
                          description: Required. Paths to all fields that the parameter
                            replaces. A field is allowed to appear in at most one
                            parameter's list of field paths. A field path is similar
                            in syntax to a .sparkJob.args
                          items:
                            type: string
                          type: array
                        name:
                          description: Required. Parameter name. The parameter name
                            is used as the key, and paired with the parameter value,
                            which are passed to the template when the template is
                            instantiated. The name must contain only capital letters
                            (A-Z), numbers (0-9), and underscores (_), and must not
                            start with a number. The maximum length is 40 characters.
                          type: string
                        validation:
                          description: Optional. Validation rules to be applied to
                            this parameter's value.
                          items:
                            properties:
                              regex:
                                description: Validation based on regular expressions.
                                items:
                                  properties:
                                    regexes:
                                      description: Required. RE2 regular expressions
                                        used to validate the parameter's value. The
                                        value must match the regex in its entirety
                                        (substring matches are not sufficient).
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              values:
                                description: Required. List of allowed values for
                                  the parameter.
                                items:
                                  properties:
                                    values:
                                      description: Required. List of allowed values
                                        for the parameter.
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                            type: object
                          type: array
                      type: object
                    type: array
                  placement:
                    description: Required. WorkflowTemplate scheduling information.
                    items:
                      properties:
                        clusterSelector:
                          description: Optional. A selector that chooses target cluster
                            for jobs based on metadata. The selector is evaluated
                            at the time each job is submitted.
                          items:
                            properties:
                              clusterLabels:
                                additionalProperties:
                                  type: string
                                description: Required. The cluster labels. Cluster
                                  must have all labels to match.
                                type: object
                              zone:
                                description: 'Optional. The zone where the Compute
                                  Engine cluster will be located. On a create request,
                                  it is required in the "global" region. If omitted
                                  in a non-global Dataproc region, the service will
                                  pick a zone in the corresponding Compute Engine
                                  region. On a get request, zone will always be present.
                                  A full URL, partial URI, or short name are valid.
                                  Examples: * https://www.googleapis.com/compute/v1/projects/
                                  * us-central1-f'
                                type: string
                            type: object
                          type: array
                        managedCluster:
                          description: A cluster that is managed by the workflow.
                          items:
                            properties:
                              clusterName:
                                description: Required. The cluster name prefix. A
                                  unique cluster name will be formed by appending
                                  a random suffix. The name must contain only lower-case
                                  letters (a-z), numbers (0-9), and hyphens (-). Must
                                  begin with a letter. Cannot begin or end with hyphen.
                                  Must consist of between 2 and 35 characters.
                                type: string
                              config:
                                description: Required. The cluster configuration.
                                items:
                                  properties:
                                    autoscalingConfig:
                                      description: Optional. Autoscaling config for
                                        the policy associated with the cluster. Cluster
                                        does not autoscale if this field is unset.
                                      items:
                                        properties:
                                          policy:
                                            description: 'Optional. The autoscaling
                                              policy used by the cluster. Only resource
                                              names including projectid and location
                                              (region) are valid. Examples: * https://www.googleapis.com/compute/v1/projects/
                                              Note that the policy must be in the
                                              same project and Dataproc region.'
                                            type: string
                                        type: object
                                      type: array
                                    encryptionConfig:
                                      description: Optional. Encryption settings for
                                        the cluster.
                                      items:
                                        properties:
                                          gcePdKmsKeyName:
                                            description: Optional. The Cloud KMS key
                                              name to use for PD disk encryption for
                                              all instances in the cluster.
                                            type: string
                                        type: object
                                      type: array
                                    endpointConfig:
                                      description: Optional. Port/endpoint configuration
                                        for this cluster
                                      items:
                                        properties:
                                          enableHttpPortAccess:
                                            description: Optional. If true, enable
                                              http access to specific ports on the
                                              cluster from external sources. Defaults
                                              to false.
                                            type: boolean
                                        type: object
                                      type: array
                                    gceClusterConfig:
                                      description: Optional. The shared Compute Engine
                                        config settings for all instances in a cluster.
                                      items:
                                        properties:
                                          internalIpOnly:
                                            description: Optional. If true, all instances
                                              in the cluster will only have internal
                                              IP addresses. By default, clusters are
                                              not restricted to internal IP addresses,
                                              and will have ephemeral external IP
                                              addresses assigned to each instance.
                                              This internal_ip_only restriction can
                                              only be enabled for subnetwork enabled
                                              networks, and all off-cluster dependencies
                                              must be configured to be accessible
                                              without external IP addresses.
                                            type: boolean
                                          metadata:
                                            additionalProperties:
                                              type: string
                                            description: The Compute Engine metadata
                                              entries to add to all instances (see
                                              (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
                                            type: object
                                          network:
                                            description: Optional. The Compute Engine
                                              network to be used for machine communications.
                                              Cannot be specified with subnetwork_uri.
                                              If neither network_uri nor subnetwork_uri
                                              is specified, the "default" network
                                              of the project is used, if it exists.
                                              Cannot be a "Custom Subnet Network"
                                              (see /regions/global/default*default`
                                            type: string
                                          nodeGroupAffinity:
                                            description: Optional. Node Group Affinity
                                              for sole-tenant clusters.
                                            items:
                                              properties:
                                                nodeGroup:
                                                  description: Required. The URI of
                                                    a sole-tenant /zones/us-central1-a/nodeGroups/node-group-1*node-group-1`
                                                  type: string
                                              type: object
                                            type: array
                                          privateIpv6GoogleAccess:
                                            description: 'Optional. The type of IPv6
                                              access for a cluster. Possible values:
                                              PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED,
                                              INHERIT_FROM_SUBNETWORK, OUTBOUND, BIDIRECTIONAL'
                                            type: string
                                          reservationAffinity:
                                            description: Optional. Reservation Affinity
                                              for consuming Zonal reservation.
                                            items:
                                              properties:
                                                consumeReservationType:
                                                  description: 'Optional. Type of
                                                    reservation to consume Possible
                                                    values: TYPE_UNSPECIFIED, NO_RESERVATION,
                                                    ANY_RESERVATION, SPECIFIC_RESERVATION'
                                                  type: string
                                                key:
                                                  description: Optional. Corresponds
                                                    to the label key of reservation
                                                    resource.
                                                  type: string
                                                values:
                                                  description: Required. List of allowed
                                                    values for the parameter.
                                                  items:
                                                    type: string
                                                  type: array
                                              type: object
                                            type: array
                                          serviceAccount:
                                            description: Optional. The (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account)
                                              is used.
                                            type: string
                                          serviceAccountScopes:
                                            description: 'Optional. The URIs of service
                                              account scopes to be included in Compute
                                              Engine instances. The following base
                                              set of scopes is always included: *
                                              https://www.googleapis.com/auth/cloud.useraccounts.readonly
                                              * https://www.googleapis.com/auth/devstorage.read_write
                                              * https://www.googleapis.com/auth/logging.write
                                              If no scopes are specified, the following
                                              defaults are also provided: * https://www.googleapis.com/auth/bigquery
                                              * https://www.googleapis.com/auth/bigtable.admin.table
                                              * https://www.googleapis.com/auth/bigtable.data
                                              * https://www.googleapis.com/auth/devstorage.full_control'
                                            items:
                                              type: string
                                            type: array
                                          shieldedInstanceConfig:
                                            description: Optional. Shielded Instance
                                              Config for clusters using Compute Engine
                                              Shielded VMs. Structure defined below.
                                            items:
                                              properties:
                                                enableIntegrityMonitoring:
                                                  description: Optional. Defines whether
                                                    instances have Integrity Monitoring
                                                    enabled.
                                                  type: boolean
                                                enableSecureBoot:
                                                  description: Optional. Defines whether
                                                    instances have Secure Boot enabled.
                                                  type: boolean
                                                enableVtpm:
                                                  description: Optional. Defines whether
                                                    instances have the vTPM enabled.
                                                  type: boolean
                                              type: object
                                            type: array
                                          subnetwork:
                                            description: 'Optional. The Compute Engine
                                              subnetwork to be used for machine communications.
                                              Cannot be specified with network_uri.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects//regions/us-east1/subnetworks/sub0
                                              * sub0'
                                            type: string
                                          tags:
                                            description: The Compute Engine tags to
                                              add to all instances (see (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
                                            items:
                                              type: string
                                            type: array
                                          zone:
                                            description: 'Optional. The zone where
                                              the Compute Engine cluster will be located.
                                              On a create request, it is required
                                              in the "global" region. If omitted in
                                              a non-global Dataproc region, the service
                                              will pick a zone in the corresponding
                                              Compute Engine region. On a get request,
                                              zone will always be present. A full
                                              URL, partial URI, or short name are
                                              valid. Examples: * https://www.googleapis.com/compute/v1/projects/
                                              * us-central1-f'
                                            type: string
                                        type: object
                                      type: array
                                    initializationActions:
                                      description: 'Optional. Commands to execute
                                        on each node after config is completed. By
                                        default, executables are run on master and
                                        all worker nodes. You can test a node''s role
                                        metadata to run an executable on a master
                                        or worker node, as shown below using curl
                                        (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google
                                        http://metadata/computeMetadata/v1/instance/attributes/dataproc-role)
                                        if ; then ... master specific actions ...
                                        else ... worker specific actions ... fi'
                                      items:
                                        properties:
                                          executableFile:
                                            description: Required. Cloud Storage URI
                                              of executable file.
                                            type: string
                                          executionTimeout:
                                            description: Optional. Amount of time
                                              executable has to complete. Default
                                              is 10 minutes (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                              Cluster creation fails with an explanatory
                                              error message (the name of the executable
                                              that caused the error and the exceeded
                                              timeout period) if the executable is
                                              not completed at end of the timeout
                                              period.
                                            type: string
                                        type: object
                                      type: array
                                    lifecycleConfig:
                                      description: Optional. Lifecycle setting for
                                        the cluster.
                                      items:
                                        properties:
                                          autoDeleteTime:
                                            description: Optional. The time when cluster
                                              will be auto-deleted (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                            type: string
                                          autoDeleteTtl:
                                            description: Optional. The lifetime duration
                                              of cluster. The cluster will be auto-deleted
                                              at the end of this period. Minimum value
                                              is 10 minutes; maximum value is 14 days
                                              (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                            type: string
                                          idleDeleteTtl:
                                            description: Optional. The duration to
                                              keep the cluster alive while idling
                                              (when no jobs are running). Passing
                                              this threshold will cause the cluster
                                              to be deleted. Minimum value is 5 minutes;
                                              maximum value is 14 days (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json).
                                            type: string
                                        type: object
                                      type: array
                                    masterConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                    secondaryWorkerConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                    securityConfig:
                                      description: Optional. Security settings for
                                        the cluster.
                                      items:
                                        properties:
                                          kerberosConfig:
                                            description: Kerberos related configuration.
                                            items:
                                              properties:
                                                crossRealmTrustAdminServer:
                                                  description: Optional. The admin
                                                    server (IP or hostname) for the
                                                    remote trusted realm in a cross
                                                    realm trust relationship.
                                                  type: string
                                                crossRealmTrustKdc:
                                                  description: Optional. The KDC (IP
                                                    or hostname) for the remote trusted
                                                    realm in a cross realm trust relationship.
                                                  type: string
                                                crossRealmTrustRealm:
                                                  description: Optional. The remote
                                                    realm the Dataproc on-cluster
                                                    KDC will trust, should the user
                                                    enable cross realm trust.
                                                  type: string
                                                crossRealmTrustSharedPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the shared password
                                                    between the on-cluster Kerberos
                                                    realm and the remote trusted realm,
                                                    in a cross realm trust relationship.
                                                  type: string
                                                enableKerberos:
                                                  description: 'Optional. Flag to
                                                    indicate whether to Kerberize
                                                    the cluster (default: false).
                                                    Set this field to true to enable
                                                    Kerberos on a cluster.'
                                                  type: boolean
                                                kdcDbKey:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the master key
                                                    of the KDC database.
                                                  type: string
                                                keyPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided key. For the
                                                    self-signed certificate, this
                                                    password is generated by Dataproc.
                                                  type: string
                                                keystore:
                                                  description: Optional. The Cloud
                                                    Storage URI of the keystore file
                                                    used for SSL encryption. If not
                                                    provided, Dataproc will provide
                                                    a self-signed certificate.
                                                  type: string
                                                keystorePassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided keystore. For
                                                    the self-signed certificate, this
                                                    password is generated by Dataproc.
                                                  type: string
                                                kmsKey:
                                                  description: Optional. The uri of
                                                    the KMS key used to encrypt various
                                                    sensitive files.
                                                  type: string
                                                realm:
                                                  description: Optional. The name
                                                    of the on-cluster Kerberos realm.
                                                    If not specified, the uppercased
                                                    domain of hostnames will be the
                                                    realm.
                                                  type: string
                                                rootPrincipalPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the root principal
                                                    password.
                                                  type: string
                                                tgtLifetimeHours:
                                                  description: Optional. The lifetime
                                                    of the ticket granting ticket,
                                                    in hours. If not specified, or
                                                    user specifies 0, then default
                                                    value 10 will be used.
                                                  type: number
                                                truststore:
                                                  description: Optional. The Cloud
                                                    Storage URI of the truststore
                                                    file used for SSL encryption.
                                                    If not provided, Dataproc will
                                                    provide a self-signed certificate.
                                                  type: string
                                                truststorePassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided truststore.
                                                    For the self-signed certificate,
                                                    this password is generated by
                                                    Dataproc.
                                                  type: string
                                              type: object
                                            type: array
                                        type: object
                                      type: array
                                    softwareConfig:
                                      description: Optional. The config settings for
                                        software inside the cluster.
                                      items:
                                        properties:
                                          imageVersion:
                                            description: Optional. The version of
                                              software inside the cluster. It must
                                              be one of the supported (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions).
                                              If unspecified, it defaults to the latest
                                              Debian version.
                                            type: string
                                          optionalComponents:
                                            items:
                                              type: string
                                            type: array
                                          properties:
                                            additionalProperties:
                                              type: string
                                            description: Optional. A mapping of property
                                              names to values, used to configure Spark
                                              SQL's SparkConf. Properties that conflict
                                              with values set by the Dataproc API
                                              may be overwritten.
                                            type: object
                                        type: object
                                      type: array
                                    stagingBucket:
                                      description: Optional. A Cloud Storage bucket
                                        used to stage job dependencies, config files,
                                        and job driver console output. If you do not
                                        specify a staging bucket, Cloud Dataproc will
                                        determine a Cloud Storage location (US, ASIA,
                                        or EU) for your cluster's staging bucket according
                                        to the Compute Engine zone where your cluster
                                        is deployed, and then create and manage this
                                        project-level, per-location bucket (see (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
                                      type: string
                                    tempBucket:
                                      description: Optional. A Cloud Storage bucket
                                        used to store ephemeral cluster and jobs data,
                                        such as Spark and MapReduce history files.
                                        If you do not specify a temp bucket, Dataproc
                                        will determine a Cloud Storage location (US,
                                        ASIA, or EU) for your cluster's temp bucket
                                        according to the Compute Engine zone where
                                        your cluster is deployed, and then create
                                        and manage this project-level, per-location
                                        bucket. The default bucket has a TTL of 90
                                        days, but you can use any TTL (or none) if
                                        you specify a bucket.
                                      type: string
                                    workerConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                  type: object
                                type: array
                              labels:
                                additionalProperties:
                                  type: string
                                description: 'Optional. The labels to associate with
                                  this cluster. Label keys must be between 1 and 63
                                  characters long, and must conform to the following
                                  PCRE regular expression: {0,63} No more than 32
                                  labels can be associated with a given cluster.'
                                type: object
                            type: object
                          type: array
                      type: object
                    type: array
                  project:
                    description: The project for the resource
                    type: string
                  version:
                    description: Optional. Used to perform a consistent read-modify-write.
                      This field should be left blank for a CreateWorkflowTemplate
                      request. It is required for an UpdateWorkflowTemplate request,
                      and must match the current server version. A typical update
                      template flow would fetch the current template with a GetWorkflowTemplate
                      request, which will return the current template with the version
                      field filled in with the current server version. The user updates
                      other fields in the template, then returns it as part of the
                      UpdateWorkflowTemplate request.
                    type: number
                required:
                - location
                type: object
              initProvider:
                description: THIS IS AN ALPHA FIELD. Do not use it in production.
                  It is not honored unless the relevant Crossplane feature flag is
                  enabled, and may be changed or removed without notice. InitProvider
                  holds the same fields as ForProvider, with the exception of Identifier
                  and other resource reference fields. The fields that are in InitProvider
                  are merged into ForProvider when the resource is created. The same
                  fields are also added to the terraform ignore_changes hook, to avoid
                  updating them after creation. This is useful for fields that are
                  required on creation, but we do not desire to update them after
                  creation, for example because of an external controller is managing
                  them, like an autoscaler.
                properties:
                  dagTimeout:
                    description: (Beta only) Optional. Timeout duration for the DAG
                      of jobs. You can use "s", "m", "h", and "d" suffixes for second,
                      minute, hour, and day duration values, respectively. The timeout
                      duration must be from 10 minutes ("10m") to 24 hours ("24h"
                      or "1d"). The timer begins when the first job is submitted.
                      If the workflow is running at the end of the timeout period,
                      any remaining jobs are cancelled, the workflow is ended, and
                      if the workflow was running on a (/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
                      the cluster is deleted.
                    type: string
                  jobs:
                    description: Required. The Directed Acyclic Graph of Jobs to submit.
                    items:
                      properties:
                        hadoopJob:
                          description: Optional. Job is a Hadoop job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainClass:
                                description: The name of the driver's main class.
                                  The jar file that contains the class must be in
                                  the default CLASSPATH or specified in jar_file_uris.
                                type: string
                              mainJarFileUri:
                                description: The HCFS URI of the jar file that contains
                                  the main class.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        hiveJob:
                          description: Optional. Job is a Hive job.
                          items:
                            properties:
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        labels:
                          additionalProperties:
                            type: string
                          description: 'Optional. The labels to associate with this
                            job. Label keys must be between 1 and 63 characters long,
                            and must conform to the following regular expression:
                            {0,63} No more than 32 labels can be associated with a
                            given job.'
                          type: object
                        pigJob:
                          description: Optional. Job is a Pig job.
                          items:
                            properties:
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        prerequisiteStepIds:
                          description: Optional. The optional list of prerequisite
                            job step_ids. If not specified, the job will start at
                            the beginning of workflow.
                          items:
                            type: string
                          type: array
                        prestoJob:
                          description: Optional. Job is a Presto job.
                          items:
                            properties:
                              clientTags:
                                description: Optional. Presto client tags to attach
                                  to this query
                                items:
                                  type: string
                                type: array
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              outputFormat:
                                description: Optional. The format in which query output
                                  will be displayed. See the Presto documentation
                                  for supported output formats
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                            type: object
                          type: array
                        pysparkJob:
                          description: Optional. Job is a PySpark job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainPythonFileUri:
                                description: Required. The HCFS URI of the main Python
                                  file to use as the driver. Must be a .py file.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              pythonFileUris:
                                description: 'Optional. HCFS file URIs of Python files
                                  to pass to the PySpark framework. Supported file
                                  types: .py, .egg, and .zip.'
                                items:
                                  type: string
                                type: array
                            type: object
                          type: array
                        scheduling:
                          description: Optional. Job scheduling configuration.
                          items:
                            properties:
                              maxFailuresPerHour:
                                description: Optional. Maximum number of times per
                                  hour a driver may be restarted as a result of driver
                                  exiting with non-zero code before job is reported
                                  failed. A job may be reported as thrashing if driver
                                  exits with non-zero code 4 times within 10 minute
                                  window. Maximum value is 10.
                                type: number
                              maxFailuresTotal:
                                description: Optional. Maximum number of times in
                                  total a driver may be restarted as a result of driver
                                  exiting with non-zero code before job is reported
                                  failed. Maximum value is 240
                                type: number
                            type: object
                          type: array
                        sparkJob:
                          description: Optional. Job is a Spark job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainClass:
                                description: The name of the driver's main class.
                                  The jar file that contains the class must be in
                                  the default CLASSPATH or specified in jar_file_uris.
                                type: string
                              mainJarFileUri:
                                description: The HCFS URI of the jar file that contains
                                  the main class.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        sparkRJob:
                          description: Optional. Job is a SparkR job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainRFileUri:
                                description: Required. The HCFS URI of the main R
                                  file to use as the driver. Must be a .R file.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        sparkSqlJob:
                          description: Optional. Job is a SparkSql job.
                          items:
                            properties:
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        stepId:
                          description: Required. The step id. The id must be unique
                            among all jobs within the template. The step id is used
                            as prefix for job id, as job goog-dataproc-workflow-step-id
                            label, and in field from other steps. The id must contain
                            only letters (a-z, A-Z), numbers (0-9), underscores (_),
                            and hyphens (-). Cannot begin or end with underscore or
                            hyphen. Must consist of between 3 and 50 characters.
                          type: string
                      type: object
                    type: array
                  labels:
                    additionalProperties:
                      type: string
                    description: 'Optional. The labels to associate with this cluster.
                      Label keys must be between 1 and 63 characters long, and must
                      conform to the following PCRE regular expression: {0,63} No
                      more than 32 labels can be associated with a given cluster.'
                    type: object
                  parameters:
                    description: Optional. Template parameters whose values are substituted
                      into the template. Values for parameters must be provided when
                      the template is instantiated.
                    items:
                      properties:
                        description:
                          description: Optional. Brief description of the parameter.
                            Must not exceed 1024 characters.
                          type: string
                        fields:
                          description: Required. Paths to all fields that the parameter
                            replaces. A field is allowed to appear in at most one
                            parameter's list of field paths. A field path is similar
                            in syntax to a .sparkJob.args
                          items:
                            type: string
                          type: array
                        name:
                          description: Required. Parameter name. The parameter name
                            is used as the key, and paired with the parameter value,
                            which are passed to the template when the template is
                            instantiated. The name must contain only capital letters
                            (A-Z), numbers (0-9), and underscores (_), and must not
                            start with a number. The maximum length is 40 characters.
                          type: string
                        validation:
                          description: Optional. Validation rules to be applied to
                            this parameter's value.
                          items:
                            properties:
                              regex:
                                description: Validation based on regular expressions.
                                items:
                                  properties:
                                    regexes:
                                      description: Required. RE2 regular expressions
                                        used to validate the parameter's value. The
                                        value must match the regex in its entirety
                                        (substring matches are not sufficient).
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              values:
                                description: Required. List of allowed values for
                                  the parameter.
                                items:
                                  properties:
                                    values:
                                      description: Required. List of allowed values
                                        for the parameter.
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                            type: object
                          type: array
                      type: object
                    type: array
                  placement:
                    description: Required. WorkflowTemplate scheduling information.
                    items:
                      properties:
                        clusterSelector:
                          description: Optional. A selector that chooses target cluster
                            for jobs based on metadata. The selector is evaluated
                            at the time each job is submitted.
                          items:
                            properties:
                              clusterLabels:
                                additionalProperties:
                                  type: string
                                description: Required. The cluster labels. Cluster
                                  must have all labels to match.
                                type: object
                              zone:
                                description: 'Optional. The zone where the Compute
                                  Engine cluster will be located. On a create request,
                                  it is required in the "global" region. If omitted
                                  in a non-global Dataproc region, the service will
                                  pick a zone in the corresponding Compute Engine
                                  region. On a get request, zone will always be present.
                                  A full URL, partial URI, or short name are valid.
                                  Examples: * https://www.googleapis.com/compute/v1/projects/
                                  * us-central1-f'
                                type: string
                            type: object
                          type: array
                        managedCluster:
                          description: A cluster that is managed by the workflow.
                          items:
                            properties:
                              clusterName:
                                description: Required. The cluster name prefix. A
                                  unique cluster name will be formed by appending
                                  a random suffix. The name must contain only lower-case
                                  letters (a-z), numbers (0-9), and hyphens (-). Must
                                  begin with a letter. Cannot begin or end with hyphen.
                                  Must consist of between 2 and 35 characters.
                                type: string
                              config:
                                description: Required. The cluster configuration.
                                items:
                                  properties:
                                    autoscalingConfig:
                                      description: Optional. Autoscaling config for
                                        the policy associated with the cluster. Cluster
                                        does not autoscale if this field is unset.
                                      items:
                                        properties:
                                          policy:
                                            description: 'Optional. The autoscaling
                                              policy used by the cluster. Only resource
                                              names including projectid and location
                                              (region) are valid. Examples: * https://www.googleapis.com/compute/v1/projects/
                                              Note that the policy must be in the
                                              same project and Dataproc region.'
                                            type: string
                                        type: object
                                      type: array
                                    encryptionConfig:
                                      description: Optional. Encryption settings for
                                        the cluster.
                                      items:
                                        properties:
                                          gcePdKmsKeyName:
                                            description: Optional. The Cloud KMS key
                                              name to use for PD disk encryption for
                                              all instances in the cluster.
                                            type: string
                                        type: object
                                      type: array
                                    endpointConfig:
                                      description: Optional. Port/endpoint configuration
                                        for this cluster
                                      items:
                                        properties:
                                          enableHttpPortAccess:
                                            description: Optional. If true, enable
                                              http access to specific ports on the
                                              cluster from external sources. Defaults
                                              to false.
                                            type: boolean
                                        type: object
                                      type: array
                                    gceClusterConfig:
                                      description: Optional. The shared Compute Engine
                                        config settings for all instances in a cluster.
                                      items:
                                        properties:
                                          internalIpOnly:
                                            description: Optional. If true, all instances
                                              in the cluster will only have internal
                                              IP addresses. By default, clusters are
                                              not restricted to internal IP addresses,
                                              and will have ephemeral external IP
                                              addresses assigned to each instance.
                                              This internal_ip_only restriction can
                                              only be enabled for subnetwork enabled
                                              networks, and all off-cluster dependencies
                                              must be configured to be accessible
                                              without external IP addresses.
                                            type: boolean
                                          metadata:
                                            additionalProperties:
                                              type: string
                                            description: The Compute Engine metadata
                                              entries to add to all instances (see
                                              (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
                                            type: object
                                          network:
                                            description: Optional. The Compute Engine
                                              network to be used for machine communications.
                                              Cannot be specified with subnetwork_uri.
                                              If neither network_uri nor subnetwork_uri
                                              is specified, the "default" network
                                              of the project is used, if it exists.
                                              Cannot be a "Custom Subnet Network"
                                              (see /regions/global/default*default`
                                            type: string
                                          nodeGroupAffinity:
                                            description: Optional. Node Group Affinity
                                              for sole-tenant clusters.
                                            items:
                                              properties:
                                                nodeGroup:
                                                  description: Required. The URI of
                                                    a sole-tenant /zones/us-central1-a/nodeGroups/node-group-1*node-group-1`
                                                  type: string
                                              type: object
                                            type: array
                                          privateIpv6GoogleAccess:
                                            description: 'Optional. The type of IPv6
                                              access for a cluster. Possible values:
                                              PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED,
                                              INHERIT_FROM_SUBNETWORK, OUTBOUND, BIDIRECTIONAL'
                                            type: string
                                          reservationAffinity:
                                            description: Optional. Reservation Affinity
                                              for consuming Zonal reservation.
                                            items:
                                              properties:
                                                consumeReservationType:
                                                  description: 'Optional. Type of
                                                    reservation to consume Possible
                                                    values: TYPE_UNSPECIFIED, NO_RESERVATION,
                                                    ANY_RESERVATION, SPECIFIC_RESERVATION'
                                                  type: string
                                                key:
                                                  description: Optional. Corresponds
                                                    to the label key of reservation
                                                    resource.
                                                  type: string
                                                values:
                                                  description: Required. List of allowed
                                                    values for the parameter.
                                                  items:
                                                    type: string
                                                  type: array
                                              type: object
                                            type: array
                                          serviceAccount:
                                            description: Optional. The (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account)
                                              is used.
                                            type: string
                                          serviceAccountScopes:
                                            description: 'Optional. The URIs of service
                                              account scopes to be included in Compute
                                              Engine instances. The following base
                                              set of scopes is always included: *
                                              https://www.googleapis.com/auth/cloud.useraccounts.readonly
                                              * https://www.googleapis.com/auth/devstorage.read_write
                                              * https://www.googleapis.com/auth/logging.write
                                              If no scopes are specified, the following
                                              defaults are also provided: * https://www.googleapis.com/auth/bigquery
                                              * https://www.googleapis.com/auth/bigtable.admin.table
                                              * https://www.googleapis.com/auth/bigtable.data
                                              * https://www.googleapis.com/auth/devstorage.full_control'
                                            items:
                                              type: string
                                            type: array
                                          shieldedInstanceConfig:
                                            description: Optional. Shielded Instance
                                              Config for clusters using Compute Engine
                                              Shielded VMs. Structure defined below.
                                            items:
                                              properties:
                                                enableIntegrityMonitoring:
                                                  description: Optional. Defines whether
                                                    instances have Integrity Monitoring
                                                    enabled.
                                                  type: boolean
                                                enableSecureBoot:
                                                  description: Optional. Defines whether
                                                    instances have Secure Boot enabled.
                                                  type: boolean
                                                enableVtpm:
                                                  description: Optional. Defines whether
                                                    instances have the vTPM enabled.
                                                  type: boolean
                                              type: object
                                            type: array
                                          subnetwork:
                                            description: 'Optional. The Compute Engine
                                              subnetwork to be used for machine communications.
                                              Cannot be specified with network_uri.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects//regions/us-east1/subnetworks/sub0
                                              * sub0'
                                            type: string
                                          tags:
                                            description: The Compute Engine tags to
                                              add to all instances (see (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
                                            items:
                                              type: string
                                            type: array
                                          zone:
                                            description: 'Optional. The zone where
                                              the Compute Engine cluster will be located.
                                              On a create request, it is required
                                              in the "global" region. If omitted in
                                              a non-global Dataproc region, the service
                                              will pick a zone in the corresponding
                                              Compute Engine region. On a get request,
                                              zone will always be present. A full
                                              URL, partial URI, or short name are
                                              valid. Examples: * https://www.googleapis.com/compute/v1/projects/
                                              * us-central1-f'
                                            type: string
                                        type: object
                                      type: array
                                    initializationActions:
                                      description: 'Optional. Commands to execute
                                        on each node after config is completed. By
                                        default, executables are run on master and
                                        all worker nodes. You can test a node''s role
                                        metadata to run an executable on a master
                                        or worker node, as shown below using curl
                                        (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google
                                        http://metadata/computeMetadata/v1/instance/attributes/dataproc-role)
                                        if ; then ... master specific actions ...
                                        else ... worker specific actions ... fi'
                                      items:
                                        properties:
                                          executableFile:
                                            description: Required. Cloud Storage URI
                                              of executable file.
                                            type: string
                                          executionTimeout:
                                            description: Optional. Amount of time
                                              executable has to complete. Default
                                              is 10 minutes (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                              Cluster creation fails with an explanatory
                                              error message (the name of the executable
                                              that caused the error and the exceeded
                                              timeout period) if the executable is
                                              not completed at end of the timeout
                                              period.
                                            type: string
                                        type: object
                                      type: array
                                    lifecycleConfig:
                                      description: Optional. Lifecycle setting for
                                        the cluster.
                                      items:
                                        properties:
                                          autoDeleteTime:
                                            description: Optional. The time when cluster
                                              will be auto-deleted (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                            type: string
                                          autoDeleteTtl:
                                            description: Optional. The lifetime duration
                                              of cluster. The cluster will be auto-deleted
                                              at the end of this period. Minimum value
                                              is 10 minutes; maximum value is 14 days
                                              (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                            type: string
                                          idleDeleteTtl:
                                            description: Optional. The duration to
                                              keep the cluster alive while idling
                                              (when no jobs are running). Passing
                                              this threshold will cause the cluster
                                              to be deleted. Minimum value is 5 minutes;
                                              maximum value is 14 days (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json).
                                            type: string
                                        type: object
                                      type: array
                                    masterConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                    secondaryWorkerConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                    securityConfig:
                                      description: Optional. Security settings for
                                        the cluster.
                                      items:
                                        properties:
                                          kerberosConfig:
                                            description: Kerberos related configuration.
                                            items:
                                              properties:
                                                crossRealmTrustAdminServer:
                                                  description: Optional. The admin
                                                    server (IP or hostname) for the
                                                    remote trusted realm in a cross
                                                    realm trust relationship.
                                                  type: string
                                                crossRealmTrustKdc:
                                                  description: Optional. The KDC (IP
                                                    or hostname) for the remote trusted
                                                    realm in a cross realm trust relationship.
                                                  type: string
                                                crossRealmTrustRealm:
                                                  description: Optional. The remote
                                                    realm the Dataproc on-cluster
                                                    KDC will trust, should the user
                                                    enable cross realm trust.
                                                  type: string
                                                crossRealmTrustSharedPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the shared password
                                                    between the on-cluster Kerberos
                                                    realm and the remote trusted realm,
                                                    in a cross realm trust relationship.
                                                  type: string
                                                enableKerberos:
                                                  description: 'Optional. Flag to
                                                    indicate whether to Kerberize
                                                    the cluster (default: false).
                                                    Set this field to true to enable
                                                    Kerberos on a cluster.'
                                                  type: boolean
                                                kdcDbKey:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the master key
                                                    of the KDC database.
                                                  type: string
                                                keyPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided key. For the
                                                    self-signed certificate, this
                                                    password is generated by Dataproc.
                                                  type: string
                                                keystore:
                                                  description: Optional. The Cloud
                                                    Storage URI of the keystore file
                                                    used for SSL encryption. If not
                                                    provided, Dataproc will provide
                                                    a self-signed certificate.
                                                  type: string
                                                keystorePassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided keystore. For
                                                    the self-signed certificate, this
                                                    password is generated by Dataproc.
                                                  type: string
                                                kmsKey:
                                                  description: Optional. The uri of
                                                    the KMS key used to encrypt various
                                                    sensitive files.
                                                  type: string
                                                realm:
                                                  description: Optional. The name
                                                    of the on-cluster Kerberos realm.
                                                    If not specified, the uppercased
                                                    domain of hostnames will be the
                                                    realm.
                                                  type: string
                                                rootPrincipalPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the root principal
                                                    password.
                                                  type: string
                                                tgtLifetimeHours:
                                                  description: Optional. The lifetime
                                                    of the ticket granting ticket,
                                                    in hours. If not specified, or
                                                    user specifies 0, then default
                                                    value 10 will be used.
                                                  type: number
                                                truststore:
                                                  description: Optional. The Cloud
                                                    Storage URI of the truststore
                                                    file used for SSL encryption.
                                                    If not provided, Dataproc will
                                                    provide a self-signed certificate.
                                                  type: string
                                                truststorePassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided truststore.
                                                    For the self-signed certificate,
                                                    this password is generated by
                                                    Dataproc.
                                                  type: string
                                              type: object
                                            type: array
                                        type: object
                                      type: array
                                    softwareConfig:
                                      description: Optional. The config settings for
                                        software inside the cluster.
                                      items:
                                        properties:
                                          imageVersion:
                                            description: Optional. The version of
                                              software inside the cluster. It must
                                              be one of the supported (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions).
                                              If unspecified, it defaults to the latest
                                              Debian version.
                                            type: string
                                          optionalComponents:
                                            items:
                                              type: string
                                            type: array
                                          properties:
                                            additionalProperties:
                                              type: string
                                            description: Optional. A mapping of property
                                              names to values, used to configure Spark
                                              SQL's SparkConf. Properties that conflict
                                              with values set by the Dataproc API
                                              may be overwritten.
                                            type: object
                                        type: object
                                      type: array
                                    stagingBucket:
                                      description: Optional. A Cloud Storage bucket
                                        used to stage job dependencies, config files,
                                        and job driver console output. If you do not
                                        specify a staging bucket, Cloud Dataproc will
                                        determine a Cloud Storage location (US, ASIA,
                                        or EU) for your cluster's staging bucket according
                                        to the Compute Engine zone where your cluster
                                        is deployed, and then create and manage this
                                        project-level, per-location bucket (see (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
                                      type: string
                                    tempBucket:
                                      description: Optional. A Cloud Storage bucket
                                        used to store ephemeral cluster and jobs data,
                                        such as Spark and MapReduce history files.
                                        If you do not specify a temp bucket, Dataproc
                                        will determine a Cloud Storage location (US,
                                        ASIA, or EU) for your cluster's temp bucket
                                        according to the Compute Engine zone where
                                        your cluster is deployed, and then create
                                        and manage this project-level, per-location
                                        bucket. The default bucket has a TTL of 90
                                        days, but you can use any TTL (or none) if
                                        you specify a bucket.
                                      type: string
                                    workerConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                  type: object
                                type: array
                              labels:
                                additionalProperties:
                                  type: string
                                description: 'Optional. The labels to associate with
                                  this cluster. Label keys must be between 1 and 63
                                  characters long, and must conform to the following
                                  PCRE regular expression: {0,63} No more than 32
                                  labels can be associated with a given cluster.'
                                type: object
                            type: object
                          type: array
                      type: object
                    type: array
                  project:
                    description: The project for the resource
                    type: string
                  version:
                    description: Optional. Used to perform a consistent read-modify-write.
                      This field should be left blank for a CreateWorkflowTemplate
                      request. It is required for an UpdateWorkflowTemplate request,
                      and must match the current server version. A typical update
                      template flow would fetch the current template with a GetWorkflowTemplate
                      request, which will return the current template with the version
                      field filled in with the current server version. The user updates
                      other fields in the template, then returns it as part of the
                      UpdateWorkflowTemplate request.
                    type: number
                type: object
              managementPolicies:
                default:
                - '*'
                description: 'THIS IS AN ALPHA FIELD. Do not use it in production.
                  It is not honored unless the relevant Crossplane feature flag is
                  enabled, and may be changed or removed without notice. ManagementPolicies
                  specify the array of actions Crossplane is allowed to take on the
                  managed and external resources. This field is planned to replace
                  the DeletionPolicy field in a future release. Currently, both could
                  be set independently and non-default values would be honored if
                  the feature flag is enabled. If both are custom, the DeletionPolicy
                  field will be ignored. See the design doc for more information:
                  https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
                  and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md'
                items:
                  description: A ManagementAction represents an action that the Crossplane
                    controllers can take on an external resource.
                  enum:
                  - Observe
                  - Create
                  - Update
                  - Delete
                  - LateInitialize
                  - '*'
                  type: string
                type: array
              providerConfigRef:
                default:
                  name: default
                description: ProviderConfigReference specifies how the provider that
                  will be used to create, observe, update, and delete this managed
                  resource should be configured.
                properties:
                  name:
                    description: Name of the referenced object.
                    type: string
                  policy:
                    description: Policies for referencing.
                    properties:
                      resolution:
                        default: Required
                        description: Resolution specifies whether resolution of this
                          reference is required. The default is 'Required', which
                          means the reconcile will fail if the reference cannot be
                          resolved. 'Optional' means this reference will be a no-op
                          if it cannot be resolved.
                        enum:
                        - Required
                        - Optional
                        type: string
                      resolve:
                        description: Resolve specifies when this reference should
                          be resolved. The default is 'IfNotPresent', which will attempt
                          to resolve the reference only when the corresponding field
                          is not present. Use 'Always' to resolve the reference on
                          every reconcile.
                        enum:
                        - Always
                        - IfNotPresent
                        type: string
                    type: object
                required:
                - name
                type: object
              providerRef:
                description: 'ProviderReference specifies the provider that will be
                  used to create, observe, update, and delete this managed resource.
                  Deprecated: Please use ProviderConfigReference, i.e. `providerConfigRef`'
                properties:
                  name:
                    description: Name of the referenced object.
                    type: string
                  policy:
                    description: Policies for referencing.
                    properties:
                      resolution:
                        default: Required
                        description: Resolution specifies whether resolution of this
                          reference is required. The default is 'Required', which
                          means the reconcile will fail if the reference cannot be
                          resolved. 'Optional' means this reference will be a no-op
                          if it cannot be resolved.
                        enum:
                        - Required
                        - Optional
                        type: string
                      resolve:
                        description: Resolve specifies when this reference should
                          be resolved. The default is 'IfNotPresent', which will attempt
                          to resolve the reference only when the corresponding field
                          is not present. Use 'Always' to resolve the reference on
                          every reconcile.
                        enum:
                        - Always
                        - IfNotPresent
                        type: string
                    type: object
                required:
                - name
                type: object
              publishConnectionDetailsTo:
                description: PublishConnectionDetailsTo specifies the connection secret
                  config which contains a name, metadata and a reference to secret
                  store config to which any connection details for this managed resource
                  should be written. Connection details frequently include the endpoint,
                  username, and password required to connect to the managed resource.
                properties:
                  configRef:
                    default:
                      name: default
                    description: SecretStoreConfigRef specifies which secret store
                      config should be used for this ConnectionSecret.
                    properties:
                      name:
                        description: Name of the referenced object.
                        type: string
                      policy:
                        description: Policies for referencing.
                        properties:
                          resolution:
                            default: Required
                            description: Resolution specifies whether resolution of
                              this reference is required. The default is 'Required',
                              which means the reconcile will fail if the reference
                              cannot be resolved. 'Optional' means this reference
                              will be a no-op if it cannot be resolved.
                            enum:
                            - Required
                            - Optional
                            type: string
                          resolve:
                            description: Resolve specifies when this reference should
                              be resolved. The default is 'IfNotPresent', which will
                              attempt to resolve the reference only when the corresponding
                              field is not present. Use 'Always' to resolve the reference
                              on every reconcile.
                            enum:
                            - Always
                            - IfNotPresent
                            type: string
                        type: object
                    required:
                    - name
                    type: object
                  metadata:
                    description: Metadata is the metadata for connection secret.
                    properties:
                      annotations:
                        additionalProperties:
                          type: string
                        description: Annotations are the annotations to be added to
                          connection secret. - For Kubernetes secrets, this will be
                          used as "metadata.annotations". - It is up to Secret Store
                          implementation for others store types.
                        type: object
                      labels:
                        additionalProperties:
                          type: string
                        description: Labels are the labels/tags to be added to connection
                          secret. - For Kubernetes secrets, this will be used as "metadata.labels".
                          - It is up to Secret Store implementation for others store
                          types.
                        type: object
                      type:
                        description: Type is the SecretType for the connection secret.
                          - Only valid for Kubernetes Secret Stores.
                        type: string
                    type: object
                  name:
                    description: Name is the name of the connection secret.
                    type: string
                required:
                - name
                type: object
              writeConnectionSecretToRef:
                description: WriteConnectionSecretToReference specifies the namespace
                  and name of a Secret to which any connection details for this managed
                  resource should be written. Connection details frequently include
                  the endpoint, username, and password required to connect to the
                  managed resource. This field is planned to be replaced in a future
                  release in favor of PublishConnectionDetailsTo. Currently, both
                  could be set independently and connection details would be published
                  to both without affecting each other.
                properties:
                  name:
                    description: Name of the secret.
                    type: string
                  namespace:
                    description: Namespace of the secret.
                    type: string
                required:
                - name
                - namespace
                type: object
            required:
            - forProvider
            type: object
            x-kubernetes-validations:
            - message: jobs is a required parameter
              rule: '!(''*'' in self.managementPolicies || ''Create'' in self.managementPolicies
                || ''Update'' in self.managementPolicies) || has(self.forProvider.jobs)
                || has(self.initProvider.jobs)'
            - message: placement is a required parameter
              rule: '!(''*'' in self.managementPolicies || ''Create'' in self.managementPolicies
                || ''Update'' in self.managementPolicies) || has(self.forProvider.placement)
                || has(self.initProvider.placement)'
          status:
            description: WorkflowTemplateStatus defines the observed state of WorkflowTemplate.
            properties:
              atProvider:
                properties:
                  createTime:
                    description: Output only. The time template was created.
                    type: string
                  dagTimeout:
                    description: (Beta only) Optional. Timeout duration for the DAG
                      of jobs. You can use "s", "m", "h", and "d" suffixes for second,
                      minute, hour, and day duration values, respectively. The timeout
                      duration must be from 10 minutes ("10m") to 24 hours ("24h"
                      or "1d"). The timer begins when the first job is submitted.
                      If the workflow is running at the end of the timeout period,
                      any remaining jobs are cancelled, the workflow is ended, and
                      if the workflow was running on a (/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
                      the cluster is deleted.
                    type: string
                  id:
                    description: an identifier for the resource with format projects/{{project}}/locations/{{location}}/workflowTemplates/{{name}}
                    type: string
                  jobs:
                    description: Required. The Directed Acyclic Graph of Jobs to submit.
                    items:
                      properties:
                        hadoopJob:
                          description: Optional. Job is a Hadoop job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainClass:
                                description: The name of the driver's main class.
                                  The jar file that contains the class must be in
                                  the default CLASSPATH or specified in jar_file_uris.
                                type: string
                              mainJarFileUri:
                                description: The HCFS URI of the jar file that contains
                                  the main class.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        hiveJob:
                          description: Optional. Job is a Hive job.
                          items:
                            properties:
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        labels:
                          additionalProperties:
                            type: string
                          description: 'Optional. The labels to associate with this
                            job. Label keys must be between 1 and 63 characters long,
                            and must conform to the following regular expression:
                            {0,63} No more than 32 labels can be associated with a
                            given job.'
                          type: object
                        pigJob:
                          description: Optional. Job is a Pig job.
                          items:
                            properties:
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        prerequisiteStepIds:
                          description: Optional. The optional list of prerequisite
                            job step_ids. If not specified, the job will start at
                            the beginning of workflow.
                          items:
                            type: string
                          type: array
                        prestoJob:
                          description: Optional. Job is a Presto job.
                          items:
                            properties:
                              clientTags:
                                description: Optional. Presto client tags to attach
                                  to this query
                                items:
                                  type: string
                                type: array
                              continueOnFailure:
                                description: Optional. Whether to continue executing
                                  queries if a query fails. The default value is false.
                                  Setting to true can be useful when executing independent
                                  parallel queries.
                                type: boolean
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              outputFormat:
                                description: Optional. The format in which query output
                                  will be displayed. See the Presto documentation
                                  for supported output formats
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                            type: object
                          type: array
                        pysparkJob:
                          description: Optional. Job is a PySpark job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainPythonFileUri:
                                description: Required. The HCFS URI of the main Python
                                  file to use as the driver. Must be a .py file.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              pythonFileUris:
                                description: 'Optional. HCFS file URIs of Python files
                                  to pass to the PySpark framework. Supported file
                                  types: .py, .egg, and .zip.'
                                items:
                                  type: string
                                type: array
                            type: object
                          type: array
                        scheduling:
                          description: Optional. Job scheduling configuration.
                          items:
                            properties:
                              maxFailuresPerHour:
                                description: Optional. Maximum number of times per
                                  hour a driver may be restarted as a result of driver
                                  exiting with non-zero code before job is reported
                                  failed. A job may be reported as thrashing if driver
                                  exits with non-zero code 4 times within 10 minute
                                  window. Maximum value is 10.
                                type: number
                              maxFailuresTotal:
                                description: Optional. Maximum number of times in
                                  total a driver may be restarted as a result of driver
                                  exiting with non-zero code before job is reported
                                  failed. Maximum value is 240
                                type: number
                            type: object
                          type: array
                        sparkJob:
                          description: Optional. Job is a Spark job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainClass:
                                description: The name of the driver's main class.
                                  The jar file that contains the class must be in
                                  the default CLASSPATH or specified in jar_file_uris.
                                type: string
                              mainJarFileUri:
                                description: The HCFS URI of the jar file that contains
                                  the main class.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        sparkRJob:
                          description: Optional. Job is a SparkR job.
                          items:
                            properties:
                              archiveUris:
                                description: 'Optional. HCFS URIs of archives to be
                                  extracted into the working directory of each executor.
                                  Supported file types: .jar, .tar, .tar.gz, .tgz,
                                  and .zip.'
                                items:
                                  type: string
                                type: array
                              args:
                                description: Optional. The arguments to pass to the
                                  driver. Do not include arguments, such as --conf,
                                  that can be set as job properties, since a collision
                                  may occur that causes an incorrect job submission.
                                items:
                                  type: string
                                type: array
                              fileUris:
                                description: Optional. HCFS URIs of files to be placed
                                  in the working directory of each executor. Useful
                                  for naively parallel tasks.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              mainRFileUri:
                                description: Required. The HCFS URI of the main R
                                  file to use as the driver. Must be a .R file.
                                type: string
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                            type: object
                          type: array
                        sparkSqlJob:
                          description: Optional. Job is a SparkSql job.
                          items:
                            properties:
                              jarFileUris:
                                description: Optional. HCFS URIs of jar files to be
                                  added to the Spark CLASSPATH.
                                items:
                                  type: string
                                type: array
                              loggingConfig:
                                description: Optional. The runtime log config for
                                  job execution.
                                items:
                                  properties:
                                    driverLogLevels:
                                      additionalProperties:
                                        type: string
                                      description: 'The per-package log levels for
                                        the driver. This may include "root" package
                                        name to configure rootLogger. Examples: ''com.google
                                        = FATAL'', ''root = INFO'', ''org.apache =
                                        DEBUG'''
                                      type: object
                                  type: object
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: Optional. A mapping of property names
                                  to values, used to configure Spark SQL's SparkConf.
                                  Properties that conflict with values set by the
                                  Dataproc API may be overwritten.
                                type: object
                              queryFileUri:
                                description: The HCFS URI of the script that contains
                                  SQL queries.
                                type: string
                              queryList:
                                description: A list of queries.
                                items:
                                  properties:
                                    queries:
                                      description: 'Required. The queries to execute.
                                        You do not need to end a query expression
                                        with a semicolon. Multiple queries can be
                                        specified in one string by separating each
                                        with a semicolon. Here is an example of a
                                        Dataproc API snippet that uses a QueryList
                                        to specify a HiveJob: "hiveJob": { "queryList":
                                        { "queries": } }'
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              scriptVariables:
                                additionalProperties:
                                  type: string
                                description: 'Optional. Mapping of query variable
                                  names to values (equivalent to the Spark SQL command:
                                  SET name="value";).'
                                type: object
                            type: object
                          type: array
                        stepId:
                          description: Required. The step id. The id must be unique
                            among all jobs within the template. The step id is used
                            as prefix for job id, as job goog-dataproc-workflow-step-id
                            label, and in field from other steps. The id must contain
                            only letters (a-z, A-Z), numbers (0-9), underscores (_),
                            and hyphens (-). Cannot begin or end with underscore or
                            hyphen. Must consist of between 3 and 50 characters.
                          type: string
                      type: object
                    type: array
                  labels:
                    additionalProperties:
                      type: string
                    description: 'Optional. The labels to associate with this cluster.
                      Label keys must be between 1 and 63 characters long, and must
                      conform to the following PCRE regular expression: {0,63} No
                      more than 32 labels can be associated with a given cluster.'
                    type: object
                  location:
                    description: The location for the resource
                    type: string
                  parameters:
                    description: Optional. Template parameters whose values are substituted
                      into the template. Values for parameters must be provided when
                      the template is instantiated.
                    items:
                      properties:
                        description:
                          description: Optional. Brief description of the parameter.
                            Must not exceed 1024 characters.
                          type: string
                        fields:
                          description: Required. Paths to all fields that the parameter
                            replaces. A field is allowed to appear in at most one
                            parameter's list of field paths. A field path is similar
                            in syntax to a .sparkJob.args
                          items:
                            type: string
                          type: array
                        name:
                          description: Required. Parameter name. The parameter name
                            is used as the key, and paired with the parameter value,
                            which are passed to the template when the template is
                            instantiated. The name must contain only capital letters
                            (A-Z), numbers (0-9), and underscores (_), and must not
                            start with a number. The maximum length is 40 characters.
                          type: string
                        validation:
                          description: Optional. Validation rules to be applied to
                            this parameter's value.
                          items:
                            properties:
                              regex:
                                description: Validation based on regular expressions.
                                items:
                                  properties:
                                    regexes:
                                      description: Required. RE2 regular expressions
                                        used to validate the parameter's value. The
                                        value must match the regex in its entirety
                                        (substring matches are not sufficient).
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                              values:
                                description: Required. List of allowed values for
                                  the parameter.
                                items:
                                  properties:
                                    values:
                                      description: Required. List of allowed values
                                        for the parameter.
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                type: array
                            type: object
                          type: array
                      type: object
                    type: array
                  placement:
                    description: Required. WorkflowTemplate scheduling information.
                    items:
                      properties:
                        clusterSelector:
                          description: Optional. A selector that chooses target cluster
                            for jobs based on metadata. The selector is evaluated
                            at the time each job is submitted.
                          items:
                            properties:
                              clusterLabels:
                                additionalProperties:
                                  type: string
                                description: Required. The cluster labels. Cluster
                                  must have all labels to match.
                                type: object
                              zone:
                                description: 'Optional. The zone where the Compute
                                  Engine cluster will be located. On a create request,
                                  it is required in the "global" region. If omitted
                                  in a non-global Dataproc region, the service will
                                  pick a zone in the corresponding Compute Engine
                                  region. On a get request, zone will always be present.
                                  A full URL, partial URI, or short name are valid.
                                  Examples: * https://www.googleapis.com/compute/v1/projects/
                                  * us-central1-f'
                                type: string
                            type: object
                          type: array
                        managedCluster:
                          description: A cluster that is managed by the workflow.
                          items:
                            properties:
                              clusterName:
                                description: Required. The cluster name prefix. A
                                  unique cluster name will be formed by appending
                                  a random suffix. The name must contain only lower-case
                                  letters (a-z), numbers (0-9), and hyphens (-). Must
                                  begin with a letter. Cannot begin or end with hyphen.
                                  Must consist of between 2 and 35 characters.
                                type: string
                              config:
                                description: Required. The cluster configuration.
                                items:
                                  properties:
                                    autoscalingConfig:
                                      description: Optional. Autoscaling config for
                                        the policy associated with the cluster. Cluster
                                        does not autoscale if this field is unset.
                                      items:
                                        properties:
                                          policy:
                                            description: 'Optional. The autoscaling
                                              policy used by the cluster. Only resource
                                              names including projectid and location
                                              (region) are valid. Examples: * https://www.googleapis.com/compute/v1/projects/
                                              Note that the policy must be in the
                                              same project and Dataproc region.'
                                            type: string
                                        type: object
                                      type: array
                                    encryptionConfig:
                                      description: Optional. Encryption settings for
                                        the cluster.
                                      items:
                                        properties:
                                          gcePdKmsKeyName:
                                            description: Optional. The Cloud KMS key
                                              name to use for PD disk encryption for
                                              all instances in the cluster.
                                            type: string
                                        type: object
                                      type: array
                                    endpointConfig:
                                      description: Optional. Port/endpoint configuration
                                        for this cluster
                                      items:
                                        properties:
                                          enableHttpPortAccess:
                                            description: Optional. If true, enable
                                              http access to specific ports on the
                                              cluster from external sources. Defaults
                                              to false.
                                            type: boolean
                                          httpPorts:
                                            additionalProperties:
                                              type: string
                                            description: Output only. The map of port
                                              descriptions to URLs. Will only be populated
                                              if enable_http_port_access is true.
                                            type: object
                                        type: object
                                      type: array
                                    gceClusterConfig:
                                      description: Optional. The shared Compute Engine
                                        config settings for all instances in a cluster.
                                      items:
                                        properties:
                                          internalIpOnly:
                                            description: Optional. If true, all instances
                                              in the cluster will only have internal
                                              IP addresses. By default, clusters are
                                              not restricted to internal IP addresses,
                                              and will have ephemeral external IP
                                              addresses assigned to each instance.
                                              This internal_ip_only restriction can
                                              only be enabled for subnetwork enabled
                                              networks, and all off-cluster dependencies
                                              must be configured to be accessible
                                              without external IP addresses.
                                            type: boolean
                                          metadata:
                                            additionalProperties:
                                              type: string
                                            description: The Compute Engine metadata
                                              entries to add to all instances (see
                                              (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
                                            type: object
                                          network:
                                            description: Optional. The Compute Engine
                                              network to be used for machine communications.
                                              Cannot be specified with subnetwork_uri.
                                              If neither network_uri nor subnetwork_uri
                                              is specified, the "default" network
                                              of the project is used, if it exists.
                                              Cannot be a "Custom Subnet Network"
                                              (see /regions/global/default*default`
                                            type: string
                                          nodeGroupAffinity:
                                            description: Optional. Node Group Affinity
                                              for sole-tenant clusters.
                                            items:
                                              properties:
                                                nodeGroup:
                                                  description: Required. The URI of
                                                    a sole-tenant /zones/us-central1-a/nodeGroups/node-group-1*node-group-1`
                                                  type: string
                                              type: object
                                            type: array
                                          privateIpv6GoogleAccess:
                                            description: 'Optional. The type of IPv6
                                              access for a cluster. Possible values:
                                              PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED,
                                              INHERIT_FROM_SUBNETWORK, OUTBOUND, BIDIRECTIONAL'
                                            type: string
                                          reservationAffinity:
                                            description: Optional. Reservation Affinity
                                              for consuming Zonal reservation.
                                            items:
                                              properties:
                                                consumeReservationType:
                                                  description: 'Optional. Type of
                                                    reservation to consume Possible
                                                    values: TYPE_UNSPECIFIED, NO_RESERVATION,
                                                    ANY_RESERVATION, SPECIFIC_RESERVATION'
                                                  type: string
                                                key:
                                                  description: Optional. Corresponds
                                                    to the label key of reservation
                                                    resource.
                                                  type: string
                                                values:
                                                  description: Required. List of allowed
                                                    values for the parameter.
                                                  items:
                                                    type: string
                                                  type: array
                                              type: object
                                            type: array
                                          serviceAccount:
                                            description: Optional. The (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account)
                                              is used.
                                            type: string
                                          serviceAccountScopes:
                                            description: 'Optional. The URIs of service
                                              account scopes to be included in Compute
                                              Engine instances. The following base
                                              set of scopes is always included: *
                                              https://www.googleapis.com/auth/cloud.useraccounts.readonly
                                              * https://www.googleapis.com/auth/devstorage.read_write
                                              * https://www.googleapis.com/auth/logging.write
                                              If no scopes are specified, the following
                                              defaults are also provided: * https://www.googleapis.com/auth/bigquery
                                              * https://www.googleapis.com/auth/bigtable.admin.table
                                              * https://www.googleapis.com/auth/bigtable.data
                                              * https://www.googleapis.com/auth/devstorage.full_control'
                                            items:
                                              type: string
                                            type: array
                                          shieldedInstanceConfig:
                                            description: Optional. Shielded Instance
                                              Config for clusters using Compute Engine
                                              Shielded VMs. Structure defined below.
                                            items:
                                              properties:
                                                enableIntegrityMonitoring:
                                                  description: Optional. Defines whether
                                                    instances have Integrity Monitoring
                                                    enabled.
                                                  type: boolean
                                                enableSecureBoot:
                                                  description: Optional. Defines whether
                                                    instances have Secure Boot enabled.
                                                  type: boolean
                                                enableVtpm:
                                                  description: Optional. Defines whether
                                                    instances have the vTPM enabled.
                                                  type: boolean
                                              type: object
                                            type: array
                                          subnetwork:
                                            description: 'Optional. The Compute Engine
                                              subnetwork to be used for machine communications.
                                              Cannot be specified with network_uri.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects//regions/us-east1/subnetworks/sub0
                                              * sub0'
                                            type: string
                                          tags:
                                            description: The Compute Engine tags to
                                              add to all instances (see (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
                                            items:
                                              type: string
                                            type: array
                                          zone:
                                            description: 'Optional. The zone where
                                              the Compute Engine cluster will be located.
                                              On a create request, it is required
                                              in the "global" region. If omitted in
                                              a non-global Dataproc region, the service
                                              will pick a zone in the corresponding
                                              Compute Engine region. On a get request,
                                              zone will always be present. A full
                                              URL, partial URI, or short name are
                                              valid. Examples: * https://www.googleapis.com/compute/v1/projects/
                                              * us-central1-f'
                                            type: string
                                        type: object
                                      type: array
                                    initializationActions:
                                      description: 'Optional. Commands to execute
                                        on each node after config is completed. By
                                        default, executables are run on master and
                                        all worker nodes. You can test a node''s role
                                        metadata to run an executable on a master
                                        or worker node, as shown below using curl
                                        (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google
                                        http://metadata/computeMetadata/v1/instance/attributes/dataproc-role)
                                        if ; then ... master specific actions ...
                                        else ... worker specific actions ... fi'
                                      items:
                                        properties:
                                          executableFile:
                                            description: Required. Cloud Storage URI
                                              of executable file.
                                            type: string
                                          executionTimeout:
                                            description: Optional. Amount of time
                                              executable has to complete. Default
                                              is 10 minutes (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                              Cluster creation fails with an explanatory
                                              error message (the name of the executable
                                              that caused the error and the exceeded
                                              timeout period) if the executable is
                                              not completed at end of the timeout
                                              period.
                                            type: string
                                        type: object
                                      type: array
                                    lifecycleConfig:
                                      description: Optional. Lifecycle setting for
                                        the cluster.
                                      items:
                                        properties:
                                          autoDeleteTime:
                                            description: Optional. The time when cluster
                                              will be auto-deleted (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                            type: string
                                          autoDeleteTtl:
                                            description: Optional. The lifetime duration
                                              of cluster. The cluster will be auto-deleted
                                              at the end of this period. Minimum value
                                              is 10 minutes; maximum value is 14 days
                                              (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                            type: string
                                          idleDeleteTtl:
                                            description: Optional. The duration to
                                              keep the cluster alive while idling
                                              (when no jobs are running). Passing
                                              this threshold will cause the cluster
                                              to be deleted. Minimum value is 5 minutes;
                                              maximum value is 14 days (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json).
                                            type: string
                                          idleStartTime:
                                            description: Output only. The time when
                                              cluster became idle (most recent job
                                              finished) and became eligible for deletion
                                              due to idleness (see JSON representation
                                              of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                            type: string
                                        type: object
                                      type: array
                                    masterConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          instanceNames:
                                            description: Output only. The list of
                                              instance names. Dataproc derives the
                                              names from cluster_name, num_instances,
                                              and the instance group.
                                            items:
                                              type: string
                                            type: array
                                          isPreemptible:
                                            description: Output only. Specifies that
                                              this instance group contains preemptible
                                              instances.
                                            type: boolean
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          managedGroupConfig:
                                            description: Output only. The config for
                                              Compute Engine Instance Group Manager
                                              that manages this group. This is only
                                              used for preemptible instance groups.
                                            items:
                                              properties:
                                                instanceGroupManagerName:
                                                  description: 'Output only. The resource
                                                    name of the workflow template,
                                                    as described in https://cloud.google.com/apis/design/resource_names.
                                                    * For projects.regions.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/regions/{region}/workflowTemplates/{template_id}
                                                    * For projects.locations.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/locations/{location}/workflowTemplates/{template_id}'
                                                  type: string
                                                instanceTemplateName:
                                                  description: 'Output only. The resource
                                                    name of the workflow template,
                                                    as described in https://cloud.google.com/apis/design/resource_names.
                                                    * For projects.regions.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/regions/{region}/workflowTemplates/{template_id}
                                                    * For projects.locations.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/locations/{location}/workflowTemplates/{template_id}'
                                                  type: string
                                              type: object
                                            type: array
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                    secondaryWorkerConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          instanceNames:
                                            description: Output only. The list of
                                              instance names. Dataproc derives the
                                              names from cluster_name, num_instances,
                                              and the instance group.
                                            items:
                                              type: string
                                            type: array
                                          isPreemptible:
                                            description: Output only. Specifies that
                                              this instance group contains preemptible
                                              instances.
                                            type: boolean
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          managedGroupConfig:
                                            description: Output only. The config for
                                              Compute Engine Instance Group Manager
                                              that manages this group. This is only
                                              used for preemptible instance groups.
                                            items:
                                              properties:
                                                instanceGroupManagerName:
                                                  description: 'Output only. The resource
                                                    name of the workflow template,
                                                    as described in https://cloud.google.com/apis/design/resource_names.
                                                    * For projects.regions.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/regions/{region}/workflowTemplates/{template_id}
                                                    * For projects.locations.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/locations/{location}/workflowTemplates/{template_id}'
                                                  type: string
                                                instanceTemplateName:
                                                  description: 'Output only. The resource
                                                    name of the workflow template,
                                                    as described in https://cloud.google.com/apis/design/resource_names.
                                                    * For projects.regions.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/regions/{region}/workflowTemplates/{template_id}
                                                    * For projects.locations.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/locations/{location}/workflowTemplates/{template_id}'
                                                  type: string
                                              type: object
                                            type: array
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                    securityConfig:
                                      description: Optional. Security settings for
                                        the cluster.
                                      items:
                                        properties:
                                          kerberosConfig:
                                            description: Kerberos related configuration.
                                            items:
                                              properties:
                                                crossRealmTrustAdminServer:
                                                  description: Optional. The admin
                                                    server (IP or hostname) for the
                                                    remote trusted realm in a cross
                                                    realm trust relationship.
                                                  type: string
                                                crossRealmTrustKdc:
                                                  description: Optional. The KDC (IP
                                                    or hostname) for the remote trusted
                                                    realm in a cross realm trust relationship.
                                                  type: string
                                                crossRealmTrustRealm:
                                                  description: Optional. The remote
                                                    realm the Dataproc on-cluster
                                                    KDC will trust, should the user
                                                    enable cross realm trust.
                                                  type: string
                                                crossRealmTrustSharedPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the shared password
                                                    between the on-cluster Kerberos
                                                    realm and the remote trusted realm,
                                                    in a cross realm trust relationship.
                                                  type: string
                                                enableKerberos:
                                                  description: 'Optional. Flag to
                                                    indicate whether to Kerberize
                                                    the cluster (default: false).
                                                    Set this field to true to enable
                                                    Kerberos on a cluster.'
                                                  type: boolean
                                                kdcDbKey:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the master key
                                                    of the KDC database.
                                                  type: string
                                                keyPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided key. For the
                                                    self-signed certificate, this
                                                    password is generated by Dataproc.
                                                  type: string
                                                keystore:
                                                  description: Optional. The Cloud
                                                    Storage URI of the keystore file
                                                    used for SSL encryption. If not
                                                    provided, Dataproc will provide
                                                    a self-signed certificate.
                                                  type: string
                                                keystorePassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided keystore. For
                                                    the self-signed certificate, this
                                                    password is generated by Dataproc.
                                                  type: string
                                                kmsKey:
                                                  description: Optional. The uri of
                                                    the KMS key used to encrypt various
                                                    sensitive files.
                                                  type: string
                                                realm:
                                                  description: Optional. The name
                                                    of the on-cluster Kerberos realm.
                                                    If not specified, the uppercased
                                                    domain of hostnames will be the
                                                    realm.
                                                  type: string
                                                rootPrincipalPassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the root principal
                                                    password.
                                                  type: string
                                                tgtLifetimeHours:
                                                  description: Optional. The lifetime
                                                    of the ticket granting ticket,
                                                    in hours. If not specified, or
                                                    user specifies 0, then default
                                                    value 10 will be used.
                                                  type: number
                                                truststore:
                                                  description: Optional. The Cloud
                                                    Storage URI of the truststore
                                                    file used for SSL encryption.
                                                    If not provided, Dataproc will
                                                    provide a self-signed certificate.
                                                  type: string
                                                truststorePassword:
                                                  description: Optional. The Cloud
                                                    Storage URI of a KMS encrypted
                                                    file containing the password to
                                                    the user provided truststore.
                                                    For the self-signed certificate,
                                                    this password is generated by
                                                    Dataproc.
                                                  type: string
                                              type: object
                                            type: array
                                        type: object
                                      type: array
                                    softwareConfig:
                                      description: Optional. The config settings for
                                        software inside the cluster.
                                      items:
                                        properties:
                                          imageVersion:
                                            description: Optional. The version of
                                              software inside the cluster. It must
                                              be one of the supported (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions).
                                              If unspecified, it defaults to the latest
                                              Debian version.
                                            type: string
                                          optionalComponents:
                                            items:
                                              type: string
                                            type: array
                                          properties:
                                            additionalProperties:
                                              type: string
                                            description: Optional. A mapping of property
                                              names to values, used to configure Spark
                                              SQL's SparkConf. Properties that conflict
                                              with values set by the Dataproc API
                                              may be overwritten.
                                            type: object
                                        type: object
                                      type: array
                                    stagingBucket:
                                      description: Optional. A Cloud Storage bucket
                                        used to stage job dependencies, config files,
                                        and job driver console output. If you do not
                                        specify a staging bucket, Cloud Dataproc will
                                        determine a Cloud Storage location (US, ASIA,
                                        or EU) for your cluster's staging bucket according
                                        to the Compute Engine zone where your cluster
                                        is deployed, and then create and manage this
                                        project-level, per-location bucket (see (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
                                      type: string
                                    tempBucket:
                                      description: Optional. A Cloud Storage bucket
                                        used to store ephemeral cluster and jobs data,
                                        such as Spark and MapReduce history files.
                                        If you do not specify a temp bucket, Dataproc
                                        will determine a Cloud Storage location (US,
                                        ASIA, or EU) for your cluster's temp bucket
                                        according to the Compute Engine zone where
                                        your cluster is deployed, and then create
                                        and manage this project-level, per-location
                                        bucket. The default bucket has a TTL of 90
                                        days, but you can use any TTL (or none) if
                                        you specify a bucket.
                                      type: string
                                    workerConfig:
                                      description: Optional. The Compute Engine config
                                        settings for additional worker instances in
                                        a cluster.
                                      items:
                                        properties:
                                          accelerators:
                                            description: Optional. The Compute Engine
                                              accelerator configuration for these
                                              instances.
                                            items:
                                              properties:
                                                acceleratorCount:
                                                  description: The number of the accelerator
                                                    cards of this type exposed to
                                                    this instance.
                                                  type: number
                                                acceleratorType:
                                                  description: Full URL, partial URI,
                                                    or short name of the accelerator
                                                    type resource to expose to this
                                                    instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                    feature, you must use the short
                                                    name of the accelerator type resource,
                                                    for example, nvidia-tesla-k80.
                                                  type: string
                                              type: object
                                            type: array
                                          diskConfig:
                                            description: Optional. Disk option config
                                              settings.
                                            items:
                                              properties:
                                                bootDiskSizeGb:
                                                  description: Optional. Size in GB
                                                    of the boot disk (default is 500GB).
                                                  type: number
                                                bootDiskType:
                                                  description: 'Optional. Type of
                                                    the boot disk (default is "pd-standard").
                                                    Valid values: "pd-ssd" (Persistent
                                                    Disk Solid State Drive) or "pd-standard"
                                                    (Persistent Disk Hard Disk Drive).'
                                                  type: string
                                                numLocalSsds:
                                                  description: Optional. Number of
                                                    attached SSDs, from 0 to 4 (default
                                                    is 0). If SSDs are not attached,
                                                    the boot disk is used to store
                                                    runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html)
                                                    data. If one or more SSDs are
                                                    attached, this runtime bulk data
                                                    is spread across them, and the
                                                    boot disk contains only basic
                                                    config and installed binaries.
                                                  type: number
                                              type: object
                                            type: array
                                          image:
                                            description: 'Optional. The Compute Engine
                                              image resource used for cluster instances.
                                              The URI can represent an image or image
                                              family. Image examples: * https://www.googleapis.com/compute/beta/projects/
                                              If the URI is unspecified, it will be
                                              inferred from SoftwareConfig.image_version
                                              or the system default.'
                                            type: string
                                          instanceNames:
                                            description: Output only. The list of
                                              instance names. Dataproc derives the
                                              names from cluster_name, num_instances,
                                              and the instance group.
                                            items:
                                              type: string
                                            type: array
                                          isPreemptible:
                                            description: Output only. Specifies that
                                              this instance group contains preemptible
                                              instances.
                                            type: boolean
                                          machineType:
                                            description: 'Optional. The Compute Engine
                                              machine type used for cluster instances.
                                              A full URL, partial URI, or short name
                                              are valid. Examples: * https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                              feature, you must use the short name
                                              of the machine type resource, for example,
                                              n1-standard-2`.'
                                            type: string
                                          managedGroupConfig:
                                            description: Output only. The config for
                                              Compute Engine Instance Group Manager
                                              that manages this group. This is only
                                              used for preemptible instance groups.
                                            items:
                                              properties:
                                                instanceGroupManagerName:
                                                  description: 'Output only. The resource
                                                    name of the workflow template,
                                                    as described in https://cloud.google.com/apis/design/resource_names.
                                                    * For projects.regions.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/regions/{region}/workflowTemplates/{template_id}
                                                    * For projects.locations.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/locations/{location}/workflowTemplates/{template_id}'
                                                  type: string
                                                instanceTemplateName:
                                                  description: 'Output only. The resource
                                                    name of the workflow template,
                                                    as described in https://cloud.google.com/apis/design/resource_names.
                                                    * For projects.regions.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/regions/{region}/workflowTemplates/{template_id}
                                                    * For projects.locations.workflowTemplates,
                                                    the resource name of the template
                                                    has the following format: projects/{project_id}/locations/{location}/workflowTemplates/{template_id}'
                                                  type: string
                                              type: object
                                            type: array
                                          minCpuPlatform:
                                            description: Optional. Specifies the minimum
                                              cpu platform for the Instance Group.
                                              See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                            type: string
                                          numInstances:
                                            description: Optional. The number of VM
                                              instances in the instance group. For
                                              master instance groups, must be set
                                              to 1.
                                            type: number
                                          preemptibility:
                                            description: 'Optional. Specifies the
                                              preemptibility of the instance group.
                                              The default value for master and worker
                                              groups is NON_PREEMPTIBLE. This default
                                              cannot be changed. The default value
                                              for secondary instances is PREEMPTIBLE.
                                              Possible values: PREEMPTIBILITY_UNSPECIFIED,
                                              NON_PREEMPTIBLE, PREEMPTIBLE'
                                            type: string
                                        type: object
                                      type: array
                                  type: object
                                type: array
                              labels:
                                additionalProperties:
                                  type: string
                                description: 'Optional. The labels to associate with
                                  this cluster. Label keys must be between 1 and 63
                                  characters long, and must conform to the following
                                  PCRE regular expression: {0,63} No more than 32
                                  labels can be associated with a given cluster.'
                                type: object
                            type: object
                          type: array
                      type: object
                    type: array
                  project:
                    description: The project for the resource
                    type: string
                  updateTime:
                    description: Output only. The time template was last updated.
                    type: string
                  version:
                    description: Optional. Used to perform a consistent read-modify-write.
                      This field should be left blank for a CreateWorkflowTemplate
                      request. It is required for an UpdateWorkflowTemplate request,
                      and must match the current server version. A typical update
                      template flow would fetch the current template with a GetWorkflowTemplate
                      request, which will return the current template with the version
                      field filled in with the current server version. The user updates
                      other fields in the template, then returns it as part of the
                      UpdateWorkflowTemplate request.
                    type: number
                type: object
              conditions:
                description: Conditions of the resource.
                items:
                  description: A Condition that may apply to a resource.
                  properties:
                    lastTransitionTime:
                      description: LastTransitionTime is the last time this condition
                        transitioned from one status to another.
                      format: date-time
                      type: string
                    message:
                      description: A Message containing details about this condition's
                        last transition from one status to another, if any.
                      type: string
                    reason:
                      description: A Reason for this condition's last transition from
                        one status to another.
                      type: string
                    status:
                      description: Status of this condition; is it currently True,
                        False, or Unknown?
                      type: string
                    type:
                      description: Type of this condition. At most one of each condition
                        type may apply to a resource at any point in time.
                      type: string
                  required:
                  - lastTransitionTime
                  - reason
                  - status
                  - type
                  type: object
                type: array
            type: object
        required:
        - spec
        type: object
    served: true
    storage: true
    subresources:
      status: {}
